{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57510f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 13 12:14:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      On   | 00000000:01:00.0 Off |                   On |\n",
      "| N/A   33C    P0    45W / 275W |                  N/A |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0   11   0   0  |   1704MiB /  4864MiB | 14      0 |  1   0    0    0    0 |\n",
      "|                  |      4MiB /  8191MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5548054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활용 gpu idx 세팅\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925ac86",
   "metadata": {},
   "source": [
    "# import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a380e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/AI4Code\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "# model import\n",
    "import torch\n",
    "# from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "data_dir = Path('./input/AI4Code')\n",
    "# data_dir = Path(f'./data/ai4code/')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c993d4b",
   "metadata": {},
   "source": [
    "# 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafb60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional code cells\n",
    "\n",
    "#preprocess.py -11\n",
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else: #code cell 개수가 지정된 n 보다 넘어가면\n",
    "        results = []\n",
    "        step = len(cells) / n #ex) 25/20 = 1.25 씩 뛰어 넘으면서 셀을 추가\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results # 마지막 셀 꼭 추가\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")): # 각 노트북에 대한 정보 저장\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fc04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric.py\n",
    "from bisect import bisect\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "            .assign(id=path.stem)\n",
    "            .rename_axis('cell_id')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a809ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.py\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.top = nn.Linear(769, 1)\n",
    "        \n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
    "        return x\n",
    "\n",
    "\n",
    "#dataset.py\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.fts[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=24,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0043b3",
   "metadata": {},
   "source": [
    "# Valid 시작!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d718459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96934/979864248.py:5: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  df_orders = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139256,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "00001756c60be8    [1862f0a6, 448eb224, 2a9e43d6, 7e2f170a, 038b763d, 77e56113, 2eefe0ef, 1ae087ab, 0beab1cd, 8ffe0b25, 9a78ab76, 0d136...\n",
       "00015c83e2717b    [2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c417225b, 51e3cd89, 2600b4eb, 75b65993, cf195f8b, 25699d02, 72b3201a, f2c75...\n",
       "Name: cell_order, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train 데이터(notebook)의 order 순서가 적혀있는 데이터(train_orders.csv) import\n",
    "# 여기서의 id는 notebook 단위\n",
    "\n",
    "#preprocess.py -2\n",
    "df_orders = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()  # cell_id가 텍스트로 붙어있음, 띄어쓰기 단위로 끊어서 리스트화\n",
    "\n",
    "print(df_orders.shape)\n",
    "df_orders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1329f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터 경로\n",
    "experiment_data_dir = f'./ai4code-999/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e169577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_mark = pd.read_csv(f'{experiment_data_dir}/train_mark.csv')#.drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n",
    "train_fts = json.load(open(f'{experiment_data_dir}/train_fts.json'))\n",
    "train_df = pd.read_csv(f'{experiment_data_dir}/train.csv')\n",
    "val_df_mark = pd.read_csv(f'{experiment_data_dir}/val_mark.csv')#.drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n",
    "val_fts = json.load(open(f'{experiment_data_dir}/val_fts.json'))\n",
    "val_df = pd.read_csv(f'{experiment_data_dir}/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9f3a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6364816, 8) (5834, 8)\n"
     ]
    }
   ],
   "source": [
    "#이후  0713\n",
    "print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8053f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2164091, 8) (1977, 8)\n"
     ]
    }
   ],
   "source": [
    "#이후  0713\n",
    "print(train_df_mark.shape, val_df_mark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce896c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer dir 지정\n",
    "tokenizer_path = f'./model/finetuned/20220703/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a4d636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md_max_len = 64\n",
    "total_max_len = 512\n",
    "batch_size = 8\n",
    "# accumulation_steps = 4\n",
    "# epochs = 4\n",
    "n_workers = 8\n",
    "\n",
    "train_ds = MarkdownDataset(train_df_mark, model_name_or_path=tokenizer_path, md_max_len=md_max_len,\n",
    "                           total_max_len=total_max_len, fts=train_fts)\n",
    "val_ds = MarkdownDataset(val_df_mark, model_name_or_path=tokenizer_path, md_max_len=md_max_len,\n",
    "                         total_max_len=total_max_len, fts=val_fts)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=n_workers,\n",
    "                          pin_memory=False, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=n_workers,\n",
    "                        pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b55826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data):\n",
    "    return tuple(d.to(device) for d in data[:-1]), data[-1].to(device)\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "    return np.concatenate(labels), np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bedd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6430b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "Graphics Device\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c99adf8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/pretrain/codebert-base \n",
      " ./model/finetuned/20220703/outputs/pytorch_model_3.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarkdownModel(\n",
       "  (model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (top): Linear(in_features=769, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import finetuned model\n",
    "\n",
    "model_path = f'./model/pretrain/codebert-base' # origin model path\n",
    "ckpt_path = os.path.join(f'./model/finetuned/20220703/outputs', 'pytorch_model_3.bin') # 체크포인트 path\n",
    "\n",
    "print(model_path, '\\n', ckpt_path)\n",
    "model = MarkdownModel(model_path)\n",
    "\n",
    "# 불러온 모델의 weight를 finetuned된 모델로 update해줌\n",
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2941ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd93a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73c8c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20915/20915 [16:39<00:00, 20.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Valid Set 결과 추출\n",
    "# codeBERT & Valid(167,313건) 기준 약 16분 걸림\n",
    "y_label, y_pred = validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be87130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((167313, 8), (167313,), (167313,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_mark.shape, y_label.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e044d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid 셋에 label, pred 추가\n",
    "val_df_mark.loc[val_df_mark[\"cell_type\"] == \"markdown\", \"label\"] = y_label\n",
    "val_df_mark.loc[val_df_mark[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2649c66",
   "metadata": {},
   "source": [
    "- encode 되어있는 ds 변환\n",
    "    - 해당 작업이 조금 오래걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "24dbcc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167313/167313 [21:05<00:00, 132.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167313"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# incode Data append\n",
    "tokenizer_forex = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "decode_lst = []\n",
    "\n",
    "for i in tqdm(range(len(val_ds))):\n",
    "    row = val_ds.__getitem__(i)\n",
    "    _encode = row[0]\n",
    "    _decode = tokenizer_forex.decode(_encode).replace('<pad>', \" \")\n",
    "#     print(_encode)\n",
    "#     print(_decode)\n",
    "#     print(row)\n",
    "    decode_lst.append(_decode)\n",
    "len(decode_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2110b3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>a3e03a94</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Always remember to delete your -now- useless data, will free up some memory.</td>\n",
       "      <td>30</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.741699</td>\n",
       "      <td>&lt;s&gt;Always remember to delete your -now- useless data, will free up some memory.&lt;/s&gt;                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>8e68c8ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>And it's all encoded. We only encoded these columns to get rid of the string data type but **if you want to train a ...</td>\n",
       "      <td>23</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.563965</td>\n",
       "      <td>&lt;s&gt;And it's all encoded. We only encoded these columns to get rid of the string data type but **if you want to train...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "0  000597ac4c6700  a3e03a94  markdown                                             Always remember to delete your -now- useless data, will free up some memory.    30    81ab937c   \n",
       "1  000597ac4c6700  8e68c8ad  markdown  And it's all encoded. We only encoded these columns to get rid of the string data type but **if you want to train a ...    23    81ab937c   \n",
       "\n",
       "  parent_id  pct_rank     label      pred                                                                                                               input_text  \n",
       "0       NaN  0.666667  0.666667  0.741699  <s>Always remember to delete your -now- useless data, will free up some memory.</s>                                 ...  \n",
       "1       NaN  0.511111  0.511111  0.563965  <s>And it's all encoded. We only encoded these columns to get rid of the string data type but **if you want to train...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_mark.loc[:,'input_text'] = decode_lst\n",
    "val_df_mark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "11929aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490240, 8) (490242, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>ede4241f</td>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np</td>\n",
       "      <td>1</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>36b989a3</td>\n",
       "      <td>code</td>\n",
       "      <td>## Function to reduce the DF size\\ndef reduce_mem_usage(df, verbose=True):\\n    numerics = ['int16', 'int32', 'int64...</td>\n",
       "      <td>3</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "0  000597ac4c6700  ede4241f      code                                                                                  import pandas as pd\\nimport numpy as np     1    81ab937c   \n",
       "1  000597ac4c6700  36b989a3      code  ## Function to reduce the DF size\\ndef reduce_mem_usage(df, verbose=True):\\n    numerics = ['int16', 'int32', 'int64...     3    81ab937c   \n",
       "\n",
       "  parent_id  pct_rank  label  pred input_text  \n",
       "0       NaN  0.022222    NaN   NaN        NaN  \n",
       "1       NaN  0.066667    NaN   NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490240</th>\n",
       "      <td>fff6c12f17ac92</td>\n",
       "      <td>7912edbd</td>\n",
       "      <td>code</td>\n",
       "      <td>sample_df.to_csv('submission.csv',index=False)</td>\n",
       "      <td>25</td>\n",
       "      <td>41d132dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490241</th>\n",
       "      <td>fff6c12f17ac92</td>\n",
       "      <td>19a20bdc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**If you like it , please upvote :)**</td>\n",
       "      <td>26</td>\n",
       "      <td>41d132dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.036133</td>\n",
       "      <td>&lt;s&gt;**If you like it, please upvote :)**&lt;/s&gt;                                                   &lt;s&gt;# Ignore  the warni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   cell_id cell_type                                          source  rank ancestor_id parent_id  pct_rank     label      pred  \\\n",
       "490240  fff6c12f17ac92  7912edbd      code  sample_df.to_csv('submission.csv',index=False)    25    41d132dc       NaN  0.925926       NaN       NaN   \n",
       "490241  fff6c12f17ac92  19a20bdc  markdown           **If you like it , please upvote :)**    26    41d132dc       NaN  0.962963  0.962963  1.036133   \n",
       "\n",
       "                                                                                                                     input_text  \n",
       "490240                                                                                                                      NaN  \n",
       "490241  <s>**If you like it, please upvote :)**</s>                                                   <s># Ignore  the warni...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Valid 셋에 label, pred 추가\n",
    "use_col = ['cell_id', 'label', 'pred', 'input_text']\n",
    "\n",
    "new_val_df = val_df.merge(val_df_mark[use_col]\n",
    "                         ,how = 'left'\n",
    "                         ,on = 'cell_id').copy()\n",
    "\n",
    "print(val_df.shape, new_val_df.shape)\n",
    "display(new_val_df.head(2))\n",
    "display(new_val_df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c676a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>ede4241f</td>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np</td>\n",
       "      <td>1</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>36b989a3</td>\n",
       "      <td>code</td>\n",
       "      <td>## Function to reduce the DF size\\ndef reduce_mem_usage(df, verbose=True):\\n    numerics = ['int16', 'int32', 'int64...</td>\n",
       "      <td>3</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>b91fc1a4</td>\n",
       "      <td>code</td>\n",
       "      <td>train = pd.read_csv(\"/kaggle/input/bdg2-class-competition/train.csv\")\\ntest = pd.read_csv(\"/kaggle/input/bdg2-class-...</td>\n",
       "      <td>5</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>97c1bb21</td>\n",
       "      <td>code</td>\n",
       "      <td>train = reduce_mem_usage(train)\\ntest = reduce_mem_usage(test)\\nwtrain = reduce_mem_usage(wtrain)\\nwtest = reduce_me...</td>\n",
       "      <td>7</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>148274fd</td>\n",
       "      <td>code</td>\n",
       "      <td>metadata.info()</td>\n",
       "      <td>8</td>\n",
       "      <td>81ab937c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490237</th>\n",
       "      <td>fff6c12f17ac92</td>\n",
       "      <td>bccd1fcb</td>\n",
       "      <td>code</td>\n",
       "      <td>learn.data.add_test(ImageList.from_df(sample_df,'../input/aptos2019-blindness-detection',folder='test_images',suffix...</td>\n",
       "      <td>22</td>\n",
       "      <td>41d132dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490238</th>\n",
       "      <td>fff6c12f17ac92</td>\n",
       "      <td>323f0b85</td>\n",
       "      <td>code</td>\n",
       "      <td>preds,y = learn.get_preds(DatasetType.Test)</td>\n",
       "      <td>23</td>\n",
       "      <td>41d132dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490239</th>\n",
       "      <td>fff6c12f17ac92</td>\n",
       "      <td>ac1e1d7f</td>\n",
       "      <td>code</td>\n",
       "      <td>sample_df.diagnosis = preds.argmax(1)\\nsample_df.head()</td>\n",
       "      <td>24</td>\n",
       "      <td>41d132dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490240</th>\n",
       "      <td>fff6c12f17ac92</td>\n",
       "      <td>7912edbd</td>\n",
       "      <td>code</td>\n",
       "      <td>sample_df.to_csv('submission.csv',index=False)</td>\n",
       "      <td>25</td>\n",
       "      <td>41d132dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490241</th>\n",
       "      <td>fff6c12f17ac92</td>\n",
       "      <td>19a20bdc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**If you like it , please upvote :)**</td>\n",
       "      <td>26</td>\n",
       "      <td>41d132dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.036133</td>\n",
       "      <td>&lt;s&gt;**If you like it, please upvote :)**&lt;/s&gt;                                                   &lt;s&gt;# Ignore  the warni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490242 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   cell_id cell_type                                                                                                                   source  rank  \\\n",
       "0       000597ac4c6700  ede4241f      code                                                                                  import pandas as pd\\nimport numpy as np     1   \n",
       "1       000597ac4c6700  36b989a3      code  ## Function to reduce the DF size\\ndef reduce_mem_usage(df, verbose=True):\\n    numerics = ['int16', 'int32', 'int64...     3   \n",
       "2       000597ac4c6700  b91fc1a4      code  train = pd.read_csv(\"/kaggle/input/bdg2-class-competition/train.csv\")\\ntest = pd.read_csv(\"/kaggle/input/bdg2-class-...     5   \n",
       "3       000597ac4c6700  97c1bb21      code  train = reduce_mem_usage(train)\\ntest = reduce_mem_usage(test)\\nwtrain = reduce_mem_usage(wtrain)\\nwtest = reduce_me...     7   \n",
       "4       000597ac4c6700  148274fd      code                                                                                                          metadata.info()     8   \n",
       "...                ...       ...       ...                                                                                                                      ...   ...   \n",
       "490237  fff6c12f17ac92  bccd1fcb      code  learn.data.add_test(ImageList.from_df(sample_df,'../input/aptos2019-blindness-detection',folder='test_images',suffix...    22   \n",
       "490238  fff6c12f17ac92  323f0b85      code                                                                              preds,y = learn.get_preds(DatasetType.Test)    23   \n",
       "490239  fff6c12f17ac92  ac1e1d7f      code                                                                  sample_df.diagnosis = preds.argmax(1)\\nsample_df.head()    24   \n",
       "490240  fff6c12f17ac92  7912edbd      code                                                                           sample_df.to_csv('submission.csv',index=False)    25   \n",
       "490241  fff6c12f17ac92  19a20bdc  markdown                                                                                    **If you like it , please upvote :)**    26   \n",
       "\n",
       "       ancestor_id parent_id  pct_rank     label      pred  \\\n",
       "0         81ab937c       NaN  0.022222  0.022222  0.022222   \n",
       "1         81ab937c       NaN  0.066667  0.066667  0.066667   \n",
       "2         81ab937c       NaN  0.111111  0.111111  0.111111   \n",
       "3         81ab937c       NaN  0.155556  0.155556  0.155556   \n",
       "4         81ab937c       NaN  0.177778  0.177778  0.177778   \n",
       "...            ...       ...       ...       ...       ...   \n",
       "490237    41d132dc       NaN  0.814815  0.814815  0.814815   \n",
       "490238    41d132dc       NaN  0.851852  0.851852  0.851852   \n",
       "490239    41d132dc       NaN  0.888889  0.888889  0.888889   \n",
       "490240    41d132dc       NaN  0.925926  0.925926  0.925926   \n",
       "490241    41d132dc       NaN  0.962963  0.962963  1.036133   \n",
       "\n",
       "                                                                                                                     input_text  \n",
       "0                                                                                                                           NaN  \n",
       "1                                                                                                                           NaN  \n",
       "2                                                                                                                           NaN  \n",
       "3                                                                                                                           NaN  \n",
       "4                                                                                                                           NaN  \n",
       "...                                                                                                                         ...  \n",
       "490237                                                                                                                      NaN  \n",
       "490238                                                                                                                      NaN  \n",
       "490239                                                                                                                      NaN  \n",
       "490240                                                                                                                      NaN  \n",
       "490241  <s>**If you like it, please upvote :)**</s>                                                   <s># Ignore  the warni...  \n",
       "\n",
       "[490242 rows x 11 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code cell label 추가\n",
    "new_val_df.label = np.where(new_val_df.label.isna(), new_val_df.pct_rank, new_val_df.label)\n",
    "new_val_df.pred = np.where(new_val_df.pred.isna(), new_val_df.pct_rank, new_val_df.pred)\n",
    "\n",
    "new_val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08254bb",
   "metadata": {},
   "source": [
    "## 결과물 print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c0dc6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric.py\n",
    "from bisect import bisect\n",
    "\n",
    "# row 단위로 kendall tau print\n",
    "def kendall_tau_byrow(gt, pred):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    \n",
    "    ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "    total_inversions += count_inversions(ranks)\n",
    "    n = len(gt)\n",
    "    total_2max += n * (n - 1)\n",
    "    return abs(1 - 4 * total_inversions / total_2max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46cd6424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid score 0.8489752778268465\n"
     ]
    }
   ],
   "source": [
    "# Valid set 성능 확인\n",
    "tmp_val_df = val_df.copy()\n",
    "tmp_val_df[\"pred\"] = tmp_val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True) #그룹별 순위 구하기, 큰 순서대로 정렬\n",
    "tmp_val_df.loc[tmp_val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred              #마크다운엔 prediction 값\n",
    "y_dummy = tmp_val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print(\"Valid score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy)) # label, pred 순으로 insert\n",
    "del tmp_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d293a882",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10520, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>[ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, 9ed48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a4651cce8f4</td>\n",
       "      <td>[2844b16f, 883db462, 9ae35818, f1dee85b, 00e71412, 3ec4ab79, 7bfe7649, 5bcfa9ad, be38feb5, f417baab, cf43b3ce, edbdd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                              label_order\n",
       "0  000597ac4c6700  [ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, 9ed48...\n",
       "1  000a4651cce8f4  [2844b16f, 883db462, 9ae35818, f1dee85b, 00e71412, 3ec4ab79, 7bfe7649, 5bcfa9ad, be38feb5, f417baab, cf43b3ce, edbdd..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10520, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>[ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, a791b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a4651cce8f4</td>\n",
       "      <td>[2844b16f, 883db462, 9ae35818, f1dee85b, 3ec4ab79, 7bfe7649, be38feb5, 00e71412, 5bcfa9ad, cf43b3ce, f417baab, edbdd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               pred_order\n",
       "0  000597ac4c6700  [ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, a791b...\n",
       "1  000a4651cce8f4  [2844b16f, 883db462, 9ae35818, f1dee85b, 3ec4ab79, 7bfe7649, be38feb5, 00e71412, 5bcfa9ad, cf43b3ce, f417baab, edbdd..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " (10520, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_order</th>\n",
       "      <th>pred_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>[ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, 9ed48...</td>\n",
       "      <td>[ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, a791b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a4651cce8f4</td>\n",
       "      <td>[2844b16f, 883db462, 9ae35818, f1dee85b, 00e71412, 3ec4ab79, 7bfe7649, 5bcfa9ad, be38feb5, f417baab, cf43b3ce, edbdd...</td>\n",
       "      <td>[2844b16f, 883db462, 9ae35818, f1dee85b, 3ec4ab79, 7bfe7649, be38feb5, 00e71412, 5bcfa9ad, cf43b3ce, f417baab, edbdd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                              label_order  \\\n",
       "0  000597ac4c6700  [ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, 9ed48...   \n",
       "1  000a4651cce8f4  [2844b16f, 883db462, 9ae35818, f1dee85b, 00e71412, 3ec4ab79, 7bfe7649, 5bcfa9ad, be38feb5, f417baab, cf43b3ce, edbdd...   \n",
       "\n",
       "                                                                                                                pred_order  \n",
       "0  [ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, a791b...  \n",
       "1  [2844b16f, 883db462, 9ae35818, f1dee85b, 3ec4ab79, 7bfe7649, be38feb5, 00e71412, 5bcfa9ad, cf43b3ce, f417baab, edbdd...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id별로 성능이 낮은건 확인\n",
    "\n",
    "label_byid = df_orders.loc[y_dummy.index].reset_index(drop=False)\n",
    "pred_byid = y_dummy.reset_index(drop=False)\n",
    "label_byid.columns = ['id', 'label_order']\n",
    "pred_byid.columns = ['id', 'pred_order']\n",
    "\n",
    "display(label_byid.shape, label_byid.head(2)\n",
    "        , pred_byid.shape, pred_byid.head(2))\n",
    "\n",
    "total_result = label_byid.merge(pred_byid\n",
    "                               ,how = 'left'\n",
    "                               ,on = 'id')\n",
    "print('\\n\\n',total_result.shape)\n",
    "total_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "520d3077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_order</th>\n",
       "      <th>pred_order</th>\n",
       "      <th>kendall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000597ac4c6700</td>\n",
       "      <td>[ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, 9ed48...</td>\n",
       "      <td>[ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, a791b...</td>\n",
       "      <td>0.957576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a4651cce8f4</td>\n",
       "      <td>[2844b16f, 883db462, 9ae35818, f1dee85b, 00e71412, 3ec4ab79, 7bfe7649, 5bcfa9ad, be38feb5, f417baab, cf43b3ce, edbdd...</td>\n",
       "      <td>[2844b16f, 883db462, 9ae35818, f1dee85b, 3ec4ab79, 7bfe7649, be38feb5, 00e71412, 5bcfa9ad, cf43b3ce, f417baab, edbdd...</td>\n",
       "      <td>0.908832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                              label_order  \\\n",
       "0  000597ac4c6700  [ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, 9ed48...   \n",
       "1  000a4651cce8f4  [2844b16f, 883db462, 9ae35818, f1dee85b, 00e71412, 3ec4ab79, 7bfe7649, 5bcfa9ad, be38feb5, f417baab, cf43b3ce, edbdd...   \n",
       "\n",
       "                                                                                                                pred_order  kendall_score  \n",
       "0  [ba54a747, ede4241f, fb42ece2, 36b989a3, 2fa559cb, b91fc1a4, 649083d4, 97c1bb21, 148274fd, 7f40f579, 92a7ccd5, a791b...       0.957576  \n",
       "1  [2844b16f, 883db462, 9ae35818, f1dee85b, 3ec4ab79, 7bfe7649, be38feb5, 00e71412, 5bcfa9ad, cf43b3ce, f417baab, edbdd...       0.908832  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과물에 kendall_score 추가\n",
    "total_result.loc[:,'kendall_score'] = [kendall_tau_byrow(n[0], n[1]) for n in total_result[['label_order', 'pred_order']].values]\n",
    "total_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e6ac107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10520.000000\n",
       "mean         0.881397\n",
       "std          0.105744\n",
       "min          0.000000\n",
       "25%          0.838235\n",
       "50%          0.907179\n",
       "75%          0.955556\n",
       "max          1.000000\n",
       "Name: kendall_score, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kendall tau score 분포 확인\n",
    "total_result.kendall_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ac346e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_tb = new_val_df[new_val_df.id == '05f96edae0f024'].copy()\n",
    "tmp_tb = tmp_tb.set_index('cell_id')\n",
    "\n",
    "# tmp_tb.loc[['9d98338d', 'ee86eac5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(total_result.kendall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4acffaf",
   "metadata": {},
   "source": [
    "### kendall tau score가 낮은 id sampleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "print(color.YELLOW + 'Hello World !' + color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e3b22b41",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_order</th>\n",
       "      <th>pred_order</th>\n",
       "      <th>kendall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>3fd66fe0a96d18</td>\n",
       "      <td>[8538920c, c4d2907b, c142a2ee, 136f872b]</td>\n",
       "      <td>[c4d2907b, 136f872b, 8538920c, c142a2ee]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>[048e2d9b, bef56024, ea556589, 20d3fe90, 69294a5a, 4b60c22a, 01f6f76b, 06d7f1db, 42485723, 9b8b36c4, 0cf7ee49, 625f2...</td>\n",
       "      <td>[20d3fe90, db4baf15, ea556589, 3cf1066f, fdb913ac, c90e3bd6, bc18d466, ba162cd7, 76a0e541, 23597b53, bf1dc93b, 4b60c...</td>\n",
       "      <td>0.025309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>[b299f9ff, 0f8c59a6, 0cd37fbf, 41cac302, 2770c4e2, f8c8c680, 39d7665b, 3919bd9a, 485ecbae, 2c527861, 8c1c0e0a, fc058...</td>\n",
       "      <td>[0cd37fbf, e0769a65, da72def6, 79b32d5e, 9432920a, 44280a92, f4a41dbe, e752cb02, cb699fd2, b299f9ff, 0f8c59a6, f54b8...</td>\n",
       "      <td>0.086542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>[92e0a22c, 6574991c, aa24cfb2, 1efd2c07, f87c1725, e7529972, db582ff6, f34383a6, d1866a2a, 2cec003c, 72b3c352, 5a932...</td>\n",
       "      <td>[92e0a22c, 1c7d3327, 5a932c2f, f87c1725, 6574991c, aa24cfb2, 49831d80, db582ff6, 2cec003c, d1866a2a, d4d1bfee, 72b3c...</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>[46fa93e3, 8515c21d, b0ea29f4, d72d0507, 553f5b96, eb2b787d, c926405c, dbbfaf24, 2708c4b8, 96b20353, 6934a531, 73da1...</td>\n",
       "      <td>[1b79d054, 2d7d9227, 9f5e2233, 46fa93e3, b0ea29f4, c472f10d, 8515c21d, d72d0507, 9c617cba, dbbfaf24, f907fbe0, 2708c...</td>\n",
       "      <td>0.131183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>[d1824dcf, 232912f8, ddfe5a63, 71945f79, 7cd943a6, 2b918080, c2978663]</td>\n",
       "      <td>[2b918080, 232912f8, ddfe5a63, 71945f79, 7cd943a6, d1824dcf, c2978663]</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8650</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>[eebc3086, 722cf377, b37481da, 712782ed, 1afd3599, 0315d35b, e92fec1b, ceb68917, b53f604a, 01514c28, 5ad53400, c2a6e...</td>\n",
       "      <td>[eebc3086, 712782ed, 5ad53400, 722cf377, b53f604a, e92fec1b, c2a6e274, 01514c28, 1afd3599, ceb68917, 0315d35b, 56f0a...</td>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>4a99d2ffd04cd6</td>\n",
       "      <td>[19bb0372, 782c7b9e, 5b019082, 067348b8, 531994ce]</td>\n",
       "      <td>[531994ce, 19bb0372, 782c7b9e, 5b019082, 067348b8]</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>[46946ca5, 022d6bd1, 3a917eba, 59da069c, 4d9f8b9f, eb012803, d4470b3c, 6296022f, 2ba8a5bf, 86943f9e, 9927ec8f, 37578...</td>\n",
       "      <td>[46946ca5, 59da069c, 77022ccd, a2422444, 7d3549e7, 55790065, 1e7ecfb4, eb012803, 3ec5ab6f, 3757841d, 1e6707b1, 022d6...</td>\n",
       "      <td>0.219873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>[502033a4, 794feada, a42f4b7e, b9d3bfc2, a706930b, 1441e3fc, ece1fb3b, d4e523f0, c6b9d271, 87794ae1, bc9d7947, 1e2a3...</td>\n",
       "      <td>[502033a4, d50e67bb, a42f4b7e, 205b4129, 7cc1fd2a, 68bcf209, 794feada, b9d3bfc2, a706930b, 1441e3fc, a6f2a408, d4e52...</td>\n",
       "      <td>0.224638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                                                                                              label_order  \\\n",
       "2643  3fd66fe0a96d18                                                                                 [8538920c, c4d2907b, c142a2ee, 136f872b]   \n",
       "3526  544655921beef7  [048e2d9b, bef56024, ea556589, 20d3fe90, 69294a5a, 4b60c22a, 01f6f76b, 06d7f1db, 42485723, 9b8b36c4, 0cf7ee49, 625f2...   \n",
       "1996  2fa3c4c997e1d1  [b299f9ff, 0f8c59a6, 0cd37fbf, 41cac302, 2770c4e2, f8c8c680, 39d7665b, 3919bd9a, 485ecbae, 2c527861, 8c1c0e0a, fc058...   \n",
       "8038  c27850f9bbcac4  [92e0a22c, 6574991c, aa24cfb2, 1efd2c07, f87c1725, e7529972, db582ff6, f34383a6, d1866a2a, 2cec003c, 72b3c352, 5a932...   \n",
       "3963  5e97933310f217  [46fa93e3, 8515c21d, b0ea29f4, d72d0507, 553f5b96, eb2b787d, c926405c, dbbfaf24, 2708c4b8, 96b20353, 6934a531, 73da1...   \n",
       "3635  56a364c9726435                                                   [d1824dcf, 232912f8, ddfe5a63, 71945f79, 7cd943a6, 2b918080, c2978663]   \n",
       "8650  d127172adeacea  [eebc3086, 722cf377, b37481da, 712782ed, 1afd3599, 0315d35b, e92fec1b, ceb68917, b53f604a, 01514c28, 5ad53400, c2a6e...   \n",
       "3093  4a99d2ffd04cd6                                                                       [19bb0372, 782c7b9e, 5b019082, 067348b8, 531994ce]   \n",
       "1353  206aadfedae1ad  [46946ca5, 022d6bd1, 3a917eba, 59da069c, 4d9f8b9f, eb012803, d4470b3c, 6296022f, 2ba8a5bf, 86943f9e, 9927ec8f, 37578...   \n",
       "984   17845073a429f3  [502033a4, 794feada, a42f4b7e, b9d3bfc2, a706930b, 1441e3fc, ece1fb3b, d4e523f0, c6b9d271, 87794ae1, bc9d7947, 1e2a3...   \n",
       "\n",
       "                                                                                                                   pred_order  kendall_score  \n",
       "2643                                                                                 [c4d2907b, 136f872b, 8538920c, c142a2ee]       0.000000  \n",
       "3526  [20d3fe90, db4baf15, ea556589, 3cf1066f, fdb913ac, c90e3bd6, bc18d466, ba162cd7, 76a0e541, 23597b53, bf1dc93b, 4b60c...       0.025309  \n",
       "1996  [0cd37fbf, e0769a65, da72def6, 79b32d5e, 9432920a, 44280a92, f4a41dbe, e752cb02, cb699fd2, b299f9ff, 0f8c59a6, f54b8...       0.086542  \n",
       "8038  [92e0a22c, 1c7d3327, 5a932c2f, f87c1725, 6574991c, aa24cfb2, 49831d80, db582ff6, 2cec003c, d1866a2a, d4d1bfee, 72b3c...       0.116667  \n",
       "3963  [1b79d054, 2d7d9227, 9f5e2233, 46fa93e3, b0ea29f4, c472f10d, 8515c21d, d72d0507, 9c617cba, dbbfaf24, f907fbe0, 2708c...       0.131183  \n",
       "3635                                                   [2b918080, 232912f8, ddfe5a63, 71945f79, 7cd943a6, d1824dcf, c2978663]       0.142857  \n",
       "8650  [eebc3086, 712782ed, 5ad53400, 722cf377, b53f604a, e92fec1b, c2a6e274, 01514c28, 1afd3599, ceb68917, 0315d35b, 56f0a...       0.179487  \n",
       "3093                                                                       [531994ce, 19bb0372, 782c7b9e, 5b019082, 067348b8]       0.200000  \n",
       "1353  [46946ca5, 59da069c, 77022ccd, a2422444, 7d3549e7, 55790065, 1e7ecfb4, eb012803, 3ec5ab6f, 3757841d, 1e6707b1, 022d6...       0.219873  \n",
       "984   [502033a4, d50e67bb, a42f4b7e, 205b4129, 7cc1fd2a, 68bcf209, 794feada, b9d3bfc2, a706930b, 1441e3fc, a6f2a408, d4e52...       0.224638  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                         3fd66fe0a96d18\n",
      "label_order      [8538920c, c4d2907b, c142a2ee, 136f872b]\n",
      "pred_order       [c4d2907b, 136f872b, 8538920c, c142a2ee]\n",
      "kendall_score                                         0.0\n",
      "Name: 2643, dtype: object\n",
      ">>> ---------- Notebook id: 3fd66fe0a96d18 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c4d2907b</th>\n",
       "      <td>3fd66fe0a96d18</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Title</td>\n",
       "      <td>1</td>\n",
       "      <td>0e15379d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.174438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136f872b</th>\n",
       "      <td>3fd66fe0a96d18</td>\n",
       "      <td>markdown</td>\n",
       "      <td>title</td>\n",
       "      <td>3</td>\n",
       "      <td>0e15379d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.345459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8538920c</th>\n",
       "      <td>3fd66fe0a96d18</td>\n",
       "      <td>code</td>\n",
       "      <td>print(\"hello world\")</td>\n",
       "      <td>0</td>\n",
       "      <td>0e15379d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c142a2ee</th>\n",
       "      <td>3fd66fe0a96d18</td>\n",
       "      <td>code</td>\n",
       "      <td>title</td>\n",
       "      <td>2</td>\n",
       "      <td>0e15379d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                source  rank ancestor_id parent_id  pct_rank  label      pred\n",
       "cell_id                                                                                                        \n",
       "c4d2907b  3fd66fe0a96d18  markdown               # Title     1    0e15379d       NaN      0.25   0.25  0.174438\n",
       "136f872b  3fd66fe0a96d18  markdown                 title     3    0e15379d       NaN      0.75   0.75  0.345459\n",
       "8538920c  3fd66fe0a96d18      code  print(\"hello world\")     0    0e15379d       NaN      0.00   0.00  0.000000\n",
       "c142a2ee  3fd66fe0a96d18      code                 title     2    0e15379d       NaN      0.50   0.50  0.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                                                                        544655921beef7\n",
      "label_order      [048e2d9b, bef56024, ea556589, 20d3fe90, 69294a5a, 4b60c22a, 01f6f76b, 06d7f1db, 42485723, 9b8b36c4, 0cf7ee49, 625f2...\n",
      "pred_order       [20d3fe90, db4baf15, ea556589, 3cf1066f, fdb913ac, c90e3bd6, bc18d466, ba162cd7, 76a0e541, 23597b53, bf1dc93b, 4b60c...\n",
      "kendall_score                                                                                                                   0.025309\n",
      "Name: 3526, dtype: object\n",
      ">>> ---------- Notebook id: 544655921beef7 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20d3fe90</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Explain inner working on logistic regression\\nhttps://satishgunjal.com/binary_lr/</td>\n",
       "      <td>3</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>-0.003082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db4baf15</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Difference between univariate, bivariate and multivariate analysis?\\n\\n* Univariate Analysis\\n\\n![Univariate_Analy...</td>\n",
       "      <td>41</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>-0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ea556589</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Explain inner working on linear regression\\nhttps://satishgunjal.com/univariate_lr/</td>\n",
       "      <td>2</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>-0.002739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3cf1066f</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Explain dimensionality reduction, and its benefits?\\n* Dimensionality reduction referes to the process of converti...</td>\n",
       "      <td>54</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdb913ac</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Explain Principal Componenet Analysis?\\n* Principal Component Analysis (PCA) is dimensionality reduction method, t...</td>\n",
       "      <td>64</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>-0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0c99587e</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Explain the scenario where both false positive and false negative are equally important\\n* In banking industry giv...</td>\n",
       "      <td>77</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>048e2d9b</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Important Tips\\n* Datascience interview questions can include questions from statistics, math, data visualization,...</td>\n",
       "      <td>0</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b8b36c4</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># What is more important model accuracy or model performance?\\n* Short answer is: Model accuracy matters the most! i...</td>\n",
       "      <td>9</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.833496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c5626e8</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>markdown</td>\n",
       "      <td># References\\n* https://www.youtube.com/watch?v=k6QWYwOvJs0&amp;t=1149s\\n* https://towardsdatascience.com/taking-the-con...</td>\n",
       "      <td>80</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.941895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babe7b75</th>\n",
       "      <td>544655921beef7</td>\n",
       "      <td>code</td>\n",
       "      <td>import math\\n\\n# define the points\\np1 = [6,5]\\np2 = [3, 2]\\n\\neuclidean_distance = math.sqrt( (p1[0]-p2[0])**2 + (p...</td>\n",
       "      <td>47</td>\n",
       "      <td>035e1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.580247</td>\n",
       "      <td>0.580247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "20d3fe90  544655921beef7  markdown                                      # Explain inner working on logistic regression\\nhttps://satishgunjal.com/binary_lr/     3    035e1579   \n",
       "db4baf15  544655921beef7  markdown  # Difference between univariate, bivariate and multivariate analysis?\\n\\n* Univariate Analysis\\n\\n![Univariate_Analy...    41    035e1579   \n",
       "ea556589  544655921beef7  markdown                                    # Explain inner working on linear regression\\nhttps://satishgunjal.com/univariate_lr/     2    035e1579   \n",
       "3cf1066f  544655921beef7  markdown  # Explain dimensionality reduction, and its benefits?\\n* Dimensionality reduction referes to the process of converti...    54    035e1579   \n",
       "fdb913ac  544655921beef7  markdown  # Explain Principal Componenet Analysis?\\n* Principal Component Analysis (PCA) is dimensionality reduction method, t...    64    035e1579   \n",
       "...                  ...       ...                                                                                                                      ...   ...         ...   \n",
       "0c99587e  544655921beef7  markdown  # Explain the scenario where both false positive and false negative are equally important\\n* In banking industry giv...    77    035e1579   \n",
       "048e2d9b  544655921beef7  markdown  # Important Tips\\n* Datascience interview questions can include questions from statistics, math, data visualization,...     0    035e1579   \n",
       "9b8b36c4  544655921beef7  markdown  # What is more important model accuracy or model performance?\\n* Short answer is: Model accuracy matters the most! i...     9    035e1579   \n",
       "3c5626e8  544655921beef7  markdown  # References\\n* https://www.youtube.com/watch?v=k6QWYwOvJs0&t=1149s\\n* https://towardsdatascience.com/taking-the-con...    80    035e1579   \n",
       "babe7b75  544655921beef7      code  import math\\n\\n# define the points\\np1 = [6,5]\\np2 = [3, 2]\\n\\neuclidean_distance = math.sqrt( (p1[0]-p2[0])**2 + (p...    47    035e1579   \n",
       "\n",
       "         parent_id  pct_rank     label      pred  \n",
       "cell_id                                           \n",
       "20d3fe90       NaN  0.037037  0.037037 -0.003082  \n",
       "db4baf15       NaN  0.506173  0.506173 -0.002829  \n",
       "ea556589       NaN  0.024691  0.024691 -0.002739  \n",
       "3cf1066f       NaN  0.666667  0.666667 -0.001030  \n",
       "fdb913ac       NaN  0.790123  0.790123 -0.000325  \n",
       "...            ...       ...       ...       ...  \n",
       "0c99587e       NaN  0.950617  0.950617  0.750000  \n",
       "048e2d9b       NaN  0.000000  0.000000  0.831055  \n",
       "9b8b36c4       NaN  0.111111  0.111111  0.833496  \n",
       "3c5626e8       NaN  0.987654  0.987654  0.941895  \n",
       "babe7b75       NaN  0.580247  0.580247  0.580247  \n",
       "\n",
       "[81 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                                                                        2fa3c4c997e1d1\n",
      "label_order      [b299f9ff, 0f8c59a6, 0cd37fbf, 41cac302, 2770c4e2, f8c8c680, 39d7665b, 3919bd9a, 485ecbae, 2c527861, 8c1c0e0a, fc058...\n",
      "pred_order       [0cd37fbf, e0769a65, da72def6, 79b32d5e, 9432920a, 44280a92, f4a41dbe, e752cb02, cb699fd2, b299f9ff, 0f8c59a6, f54b8...\n",
      "kendall_score                                                                                                                   0.086542\n",
      "Name: 1996, dtype: object\n",
      ">>> ---------- Notebook id: 2fa3c4c997e1d1 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0cd37fbf</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Keras 전처리 층 API는 개발자들이 Keras 고유의 입력 처리 파이프라인을 만들 수 있게 해줍니다. 이 입력 처리 파이프라인들은 Keras가 아닌 작업 흐름 안에서 독립적인 사전 처리 코드로써 사용되고...</td>\n",
       "      <td>2</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.008728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e0769a65</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>[바닥에서 부터 이미지 분류](https://keras.io/examples/vision/image_classification_from_scratch/) 예제에서 비슷한 설정 활동을 볼 수 있습니다.</td>\n",
       "      <td>45</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.032257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da72def6</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>[바닥에서 부터 텍스트 분류](https://keras.io/examples/nlp/text_classification_from_scratch/) 예제에서 `Embedding` 방식과 결합된 `TextVect...</td>\n",
       "      <td>62</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.036621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79b32d5e</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport tensorflow as tf\\nfrom tensorflow.keras.layers.experimental import preprocessing\\n\\ndata ...</td>\n",
       "      <td>21</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9432920a</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## 추론 기간에 모델 안에서 전처리 수행의 장점</td>\n",
       "      <td>36</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.109009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beb20d89</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>`adapt()` 메소드를 통해 학습 데이터에 전처리 층을 노출시킴으로써 상태를 설정할 수 있습니다:</td>\n",
       "      <td>20</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.734863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df40cc17</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>* `RandomCrop` 층\\n* `RandomFlip` 층\\n* `RandomTranslation` 층\\n* `RandomRotation` 층\\n* `RandomZoom` 층\\n* `RandomHeight...</td>\n",
       "      <td>15</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.798828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c42dbd1</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>code</td>\n",
       "      <td># 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        ...</td>\n",
       "      <td>61</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.871429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d52944d9</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>code</td>\n",
       "      <td># 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        ...</td>\n",
       "      <td>66</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2a906c6</th>\n",
       "      <td>2fa3c4c997e1d1</td>\n",
       "      <td>code</td>\n",
       "      <td># 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        ...</td>\n",
       "      <td>69</td>\n",
       "      <td>074f30fd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.985714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "0cd37fbf  2fa3c4c997e1d1  markdown  Keras 전처리 층 API는 개발자들이 Keras 고유의 입력 처리 파이프라인을 만들 수 있게 해줍니다. 이 입력 처리 파이프라인들은 Keras가 아닌 작업 흐름 안에서 독립적인 사전 처리 코드로써 사용되고...     2    074f30fd   \n",
       "e0769a65  2fa3c4c997e1d1  markdown          [바닥에서 부터 이미지 분류](https://keras.io/examples/vision/image_classification_from_scratch/) 예제에서 비슷한 설정 활동을 볼 수 있습니다.    45    074f30fd   \n",
       "da72def6  2fa3c4c997e1d1  markdown  [바닥에서 부터 텍스트 분류](https://keras.io/examples/nlp/text_classification_from_scratch/) 예제에서 `Embedding` 방식과 결합된 `TextVect...    62    074f30fd   \n",
       "79b32d5e  2fa3c4c997e1d1      code  import numpy as np\\nimport tensorflow as tf\\nfrom tensorflow.keras.layers.experimental import preprocessing\\n\\ndata ...    21    074f30fd   \n",
       "9432920a  2fa3c4c997e1d1  markdown                                                                                              ## 추론 기간에 모델 안에서 전처리 수행의 장점    36    074f30fd   \n",
       "...                  ...       ...                                                                                                                      ...   ...         ...   \n",
       "beb20d89  2fa3c4c997e1d1  markdown                                                                 `adapt()` 메소드를 통해 학습 데이터에 전처리 층을 노출시킴으로써 상태를 설정할 수 있습니다:    20    074f30fd   \n",
       "df40cc17  2fa3c4c997e1d1  markdown  * `RandomCrop` 층\\n* `RandomFlip` 층\\n* `RandomTranslation` 층\\n* `RandomRotation` 층\\n* `RandomZoom` 층\\n* `RandomHeight...    15    074f30fd   \n",
       "1c42dbd1  2fa3c4c997e1d1      code  # 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        ...    61    074f30fd   \n",
       "d52944d9  2fa3c4c997e1d1      code  # 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        ...    66    074f30fd   \n",
       "f2a906c6  2fa3c4c997e1d1      code  # 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        ...    69    074f30fd   \n",
       "\n",
       "         parent_id  pct_rank     label      pred  \n",
       "cell_id                                           \n",
       "0cd37fbf       NaN  0.028571  0.028571  0.008728  \n",
       "e0769a65       NaN  0.642857  0.642857  0.032257  \n",
       "da72def6       NaN  0.885714  0.885714  0.036621  \n",
       "79b32d5e       NaN  0.300000  0.300000  0.300000  \n",
       "9432920a       NaN  0.514286  0.514286  0.109009  \n",
       "...            ...       ...       ...       ...  \n",
       "beb20d89       NaN  0.285714  0.285714  0.734863  \n",
       "df40cc17       NaN  0.214286  0.214286  0.798828  \n",
       "1c42dbd1       NaN  0.871429  0.871429  0.871429  \n",
       "d52944d9       NaN  0.942857  0.942857  0.942857  \n",
       "f2a906c6       NaN  0.985714  0.985714  0.985714  \n",
       "\n",
       "[70 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                                                                        c27850f9bbcac4\n",
      "label_order      [92e0a22c, 6574991c, aa24cfb2, 1efd2c07, f87c1725, e7529972, db582ff6, f34383a6, d1866a2a, 2cec003c, 72b3c352, 5a932...\n",
      "pred_order       [92e0a22c, 1c7d3327, 5a932c2f, f87c1725, 6574991c, aa24cfb2, 49831d80, db582ff6, 2cec003c, d1866a2a, d4d1bfee, 72b3c...\n",
      "kendall_score                                                                                                                   0.116667\n",
      "Name: 8038, dtype: object\n",
      ">>> ---------- Notebook id: c27850f9bbcac4 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92e0a22c</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Mathematics of Support Vector Machines</td>\n",
       "      <td>0</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.005901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c7d3327</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Kernel Trick</td>\n",
       "      <td>12</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>-0.005646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a932c2f</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Lagrangian Multipliers\\n\\nThe general idea is to transform a constrained optimization objective into an unconstrai...</td>\n",
       "      <td>11</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.014542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f87c1725</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Lets look at mathematical expression defining the conditions\\n\\nThis notebook is inspired by MIT course on SVM, t...</td>\n",
       "      <td>4</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.064209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574991c</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Topics covered in this notebook\\n* The SVC Algorithm\\n* The Lagrange Multiplier\\n* Kernel Trick</td>\n",
       "      <td>1</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa24cfb2</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td># The Algorithm\\n\\nI will use very basic level examples starting with 2D space to explain this:\\n\\nLets say that you...</td>\n",
       "      <td>2</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.155762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49831d80</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Types of kernel\\n\\n$K(xi,xj) = (xi.xj +c)^d$- This is example of polynomial kernel where dot product of original ...</td>\n",
       "      <td>15</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.247559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db582ff6</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>The shortest distance between a point a plane is given by the orthogonal projection of a line into another line, i.e...</td>\n",
       "      <td>6</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.356201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2cec003c</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![svm4.PNG](attachment:svm4.PNG)</td>\n",
       "      <td>9</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.373047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1866a2a</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>### Changing the one reference point to origin</td>\n",
       "      <td>8</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.430176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4d1bfee</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>When we have a problem where two classes are not linearly seperable, then we use kernel trick to transform lower dim...</td>\n",
       "      <td>14</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.452881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72b3c352</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Now x is at origin hence hence $r=\\frac{g(x)}{||w_0||}$ will now become $r=\\frac{b_0}{||w_0||}$ this is the optimal ...</td>\n",
       "      <td>10</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.560059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f34383a6</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We can rewrite our equation as $g(x)=w_0^Tx+b_0$ and, the distance of x from plane will be normal projection of x on...</td>\n",
       "      <td>7</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.562988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7529972</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's say that our roses are represented by d = 1 and weed as d=-1 and on the road we do not have any of weed and ro...</td>\n",
       "      <td>5</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.563965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1efd2c07</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Now you try to maximize the width of the raod so that weeds have good seperation from roses.But you have to also mak...</td>\n",
       "      <td>3</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.614258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6c38d8d4</th>\n",
       "      <td>c27850f9bbcac4</td>\n",
       "      <td>code</td>\n",
       "      <td>###construct a non linear decision boundary####\\nimport numpy as np \\nimport sklearn \\nimport matplotlib.pyplot as p...</td>\n",
       "      <td>13</td>\n",
       "      <td>541f28d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "92e0a22c  c27850f9bbcac4  markdown                                                                                 # Mathematics of Support Vector Machines     0    541f28d7   \n",
       "1c7d3327  c27850f9bbcac4  markdown                                                                                                           # Kernel Trick    12    541f28d7   \n",
       "5a932c2f  c27850f9bbcac4  markdown  # Lagrangian Multipliers\\n\\nThe general idea is to transform a constrained optimization objective into an unconstrai...    11    541f28d7   \n",
       "f87c1725  c27850f9bbcac4  markdown  ## Lets look at mathematical expression defining the conditions\\n\\nThis notebook is inspired by MIT course on SVM, t...     4    541f28d7   \n",
       "6574991c  c27850f9bbcac4  markdown                       ## Topics covered in this notebook\\n* The SVC Algorithm\\n* The Lagrange Multiplier\\n* Kernel Trick     1    541f28d7   \n",
       "aa24cfb2  c27850f9bbcac4  markdown  # The Algorithm\\n\\nI will use very basic level examples starting with 2D space to explain this:\\n\\nLets say that you...     2    541f28d7   \n",
       "49831d80  c27850f9bbcac4  markdown  ## Types of kernel\\n\\n$K(xi,xj) = (xi.xj +c)^d$- This is example of polynomial kernel where dot product of original ...    15    541f28d7   \n",
       "db582ff6  c27850f9bbcac4  markdown  The shortest distance between a point a plane is given by the orthogonal projection of a line into another line, i.e...     6    541f28d7   \n",
       "2cec003c  c27850f9bbcac4  markdown                                                                                         ![svm4.PNG](attachment:svm4.PNG)     9    541f28d7   \n",
       "d1866a2a  c27850f9bbcac4  markdown                                                                           ### Changing the one reference point to origin     8    541f28d7   \n",
       "d4d1bfee  c27850f9bbcac4  markdown  When we have a problem where two classes are not linearly seperable, then we use kernel trick to transform lower dim...    14    541f28d7   \n",
       "72b3c352  c27850f9bbcac4  markdown  Now x is at origin hence hence $r=\\frac{g(x)}{||w_0||}$ will now become $r=\\frac{b_0}{||w_0||}$ this is the optimal ...    10    541f28d7   \n",
       "f34383a6  c27850f9bbcac4  markdown  We can rewrite our equation as $g(x)=w_0^Tx+b_0$ and, the distance of x from plane will be normal projection of x on...     7    541f28d7   \n",
       "e7529972  c27850f9bbcac4  markdown  Let's say that our roses are represented by d = 1 and weed as d=-1 and on the road we do not have any of weed and ro...     5    541f28d7   \n",
       "1efd2c07  c27850f9bbcac4  markdown  Now you try to maximize the width of the raod so that weeds have good seperation from roses.But you have to also mak...     3    541f28d7   \n",
       "6c38d8d4  c27850f9bbcac4      code  ###construct a non linear decision boundary####\\nimport numpy as np \\nimport sklearn \\nimport matplotlib.pyplot as p...    13    541f28d7   \n",
       "\n",
       "         parent_id  pct_rank   label      pred  \n",
       "cell_id                                         \n",
       "92e0a22c       NaN    0.0000  0.0000 -0.005901  \n",
       "1c7d3327       NaN    0.7500  0.7500 -0.005646  \n",
       "5a932c2f       NaN    0.6875  0.6875  0.014542  \n",
       "f87c1725       NaN    0.2500  0.2500  0.064209  \n",
       "6574991c       NaN    0.0625  0.0625  0.125000  \n",
       "aa24cfb2       NaN    0.1250  0.1250  0.155762  \n",
       "49831d80       NaN    0.9375  0.9375  0.247559  \n",
       "db582ff6       NaN    0.3750  0.3750  0.356201  \n",
       "2cec003c       NaN    0.5625  0.5625  0.373047  \n",
       "d1866a2a       NaN    0.5000  0.5000  0.430176  \n",
       "d4d1bfee       NaN    0.8750  0.8750  0.452881  \n",
       "72b3c352       NaN    0.6250  0.6250  0.560059  \n",
       "f34383a6       NaN    0.4375  0.4375  0.562988  \n",
       "e7529972       NaN    0.3125  0.3125  0.563965  \n",
       "1efd2c07       NaN    0.1875  0.1875  0.614258  \n",
       "6c38d8d4       NaN    0.8125  0.8125  0.812500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                                                                        5e97933310f217\n",
      "label_order      [46fa93e3, 8515c21d, b0ea29f4, d72d0507, 553f5b96, eb2b787d, c926405c, dbbfaf24, 2708c4b8, 96b20353, 6934a531, 73da1...\n",
      "pred_order       [1b79d054, 2d7d9227, 9f5e2233, 46fa93e3, b0ea29f4, c472f10d, 8515c21d, d72d0507, 9c617cba, dbbfaf24, f907fbe0, 2708c...\n",
      "kendall_score                                                                                                                   0.131183\n",
      "Name: 3963, dtype: object\n",
      ">>> ---------- Notebook id: 5e97933310f217 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1b79d054</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># BIAS in AI\\n\\n* Each neuron has bias.\\n* The flexibility of the model will be rised. \\n\\n&lt;a &gt;&lt;img src=\"https://i.i...</td>\n",
       "      <td>19</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>-0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d7d9227</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># What is Kernel?\\n\\nThe Kernel helps us separate data with a non-linear decision boundary using a linear classifier...</td>\n",
       "      <td>28</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>-0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9f5e2233</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Vanishing Gradient \\nCHeck the code example : https://cs224d.stanford.edu/notebooks/vanishing_grad_example.html\\nW...</td>\n",
       "      <td>18</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.011536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46fa93e3</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;div class=\"list-group\" id=\"list-tab\" role=\"tablist\"&gt;\\n  &lt;h3 class=\"list-group-item list-group-item-action active\" d...</td>\n",
       "      <td>0</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0ea29f4</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"super\"&gt;&lt;/a&gt; \\n\\n# **1. Supervised Learning**\\n\\nYou give input data. \\n\\nEx for Supervised Learning:\\n\\n**Se...</td>\n",
       "      <td>2</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.054230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c472f10d</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Regularization-2\\n\\n   ## 1. Ridge Regression\\n\\n&lt;a &gt;&lt;img src=\"https://i.ibb.co/y4SJq5k/Screenshot-2021-07-14-at-2...</td>\n",
       "      <td>20</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.057678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515c21d</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"1\"&gt;&lt;/a&gt; \\n# **Four Categories of Machine Learning** \\n\\n    \\n \\n1. Supervised Learning\\n2. Unsupervised Lea...</td>\n",
       "      <td>1</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.058167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d72d0507</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"unsuper\"&gt;&lt;/a&gt;\\n\\n# **2. Unsupervised Learning**\\n\\n    \"Unsupervised Learning is the bread and butter of dat...</td>\n",
       "      <td>3</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.141968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9c617cba</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Leaky Relu\\n\\n&gt;  **Leaky Rectified Linear Unit**, or Leaky ReLU, is a type of activation function based on a ReLU,...</td>\n",
       "      <td>27</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.226196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbbfaf24</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>code</td>\n",
       "      <td>num_validation_samples = 20000\\n\\nnp.random.shuffle(data)\\n\\n#Defining the validatian set.\\nvalidation_data= data[:n...</td>\n",
       "      <td>7</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f907fbe0</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#   **BATCH SIZE**\\n\\n&gt;     Number of the samples that will be passed through to the network at one time.\\n\\n&lt;a &gt;&lt;im...</td>\n",
       "      <td>21</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.264404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708c4b8</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"kfo\"&gt;&lt;/a&gt;\\n# 2. K-fold Validation\\n\\n    When we have too few samples for hold-out validation.</td>\n",
       "      <td>8</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.348389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a807ba9</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"zp\"&gt;&lt;/a&gt;\\n\\n# &lt;p style=\"color:green;font-size:25px \" &gt;Zero Padding &lt;/p&gt; \\n\\n\\n&lt;a &gt;&lt;img src=\"https://i.ibb.co...</td>\n",
       "      <td>16</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.408936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408a3e6</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># **Sequential or Functional Model**</td>\n",
       "      <td>25</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.414551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8c358a5c</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![image.png](attachment:c0b9f51e-2abb-4960-bde7-bfabddee8f6e.png)</td>\n",
       "      <td>29</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.415527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f98ac2d0</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"reg1\"&gt;&lt;/a&gt;\\n\\n# &lt;p style=\"color:purple;font-size:30px \"&gt;Regularization-1 &lt;/p&gt; Regularization techniques are ...</td>\n",
       "      <td>13</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.422363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c926405c</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"3\"&gt;&lt;/a&gt;\\n&lt;p style=\"color:blue;font-size:20px \" &gt;Three classic evalution model: &lt;/p&gt; \\n\\n# EVALUTATION RECIPE...</td>\n",
       "      <td>6</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.432617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f87d78d5</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># &lt;p style=\"color:green;font-size:25px \" &gt;Max Pooling  &lt;/p&gt; &lt;a &gt;&lt;img src=\"https://i.ibb.co/5Lzy1r1/Screenshot-from-2...</td>\n",
       "      <td>17</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.461426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934a531</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"it\"&gt;&lt;/a&gt;\\n\\n# 3. Iterated K-fold\\n\\n    We can evaluate our model \"as precisely as possible\".</td>\n",
       "      <td>10</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96b20353</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>code</td>\n",
       "      <td>k = 4 #or 3,5..\\nnum_validation_samples = len(data)//k\\n\\nnp.random.shuffle(data)\\n\\nvalidation_scores = []\\n\\nfor f...</td>\n",
       "      <td>9</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553f5b96</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"selfsup\"&gt;&lt;/a&gt;\\n\\n# **3. Self-supervised Learning**\\n\\n    \"It is a supervised learning but without human-ann...</td>\n",
       "      <td>4</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce5cffa9</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># &lt;p style=\"color:blue;font-size:25px \" &gt;HyperParameter &lt;/p&gt; A hyperparameter is a parameter of a learning algorithm...</td>\n",
       "      <td>14</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.538086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baa9655a</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**There are two ways to build Keras models: sequential and functional.**\\n \\nThe sequential API allows you to create...</td>\n",
       "      <td>26</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.556152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73ff316f</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"lr\"&gt;&lt;/a&gt;\\n\\n# &lt;p style=\"color:blue;font-size:25px \" &gt;Learning Rate &lt;/p&gt; Learning Rate symbolizes the step we...</td>\n",
       "      <td>15</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5d41cbd</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># DATA AUGEMENTATION \\n</td>\n",
       "      <td>23</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.604004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8430e33</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Fine-tuning\\n    If it has learned the knowledge of recognizing cars, it can also notice trucks later. This is cal...</td>\n",
       "      <td>22</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.624512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb2b787d</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"RL\"&gt;&lt;/a&gt;\\n\\n# **4. Reinforcement Learning**\\n\\n![image.png](attachment:7db13489-ac8a-488a-a4d4-b1502a93feba....</td>\n",
       "      <td>5</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.630859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73da14f7</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import Stratif...</td>\n",
       "      <td>11</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8c9220b5</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;a id =\"not\"&gt;&lt;/a&gt;\\n\\n# &lt;p style=\"color:red;font-size:20px \" &gt;NOTES: &lt;/p&gt; \\n\\n&gt; 1. No information regarding the test ...</td>\n",
       "      <td>12</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95ec6c68</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>markdown</td>\n",
       "      <td>\\nSources: \\n\\n[1] Yakup Genç, GTU Derin Öğrenme Ders Notları\\n\\n[2] Cristina Scheau, Regularization in deep learnin...</td>\n",
       "      <td>30</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.950684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202615e2</th>\n",
       "      <td>5e97933310f217</td>\n",
       "      <td>code</td>\n",
       "      <td>#DATA AUGEMENTATION \\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport os\\nimport random\\nimport tensorfl...</td>\n",
       "      <td>24</td>\n",
       "      <td>8bb61997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "1b79d054  5e97933310f217  markdown  # BIAS in AI\\n\\n* Each neuron has bias.\\n* The flexibility of the model will be rised. \\n\\n<a ><img src=\"https://i.i...    19    8bb61997   \n",
       "2d7d9227  5e97933310f217  markdown  # What is Kernel?\\n\\nThe Kernel helps us separate data with a non-linear decision boundary using a linear classifier...    28    8bb61997   \n",
       "9f5e2233  5e97933310f217  markdown  # Vanishing Gradient \\nCHeck the code example : https://cs224d.stanford.edu/notebooks/vanishing_grad_example.html\\nW...    18    8bb61997   \n",
       "46fa93e3  5e97933310f217  markdown  <div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\\n  <h3 class=\"list-group-item list-group-item-action active\" d...     0    8bb61997   \n",
       "b0ea29f4  5e97933310f217  markdown  <a id =\"super\"></a> \\n\\n# **1. Supervised Learning**\\n\\nYou give input data. \\n\\nEx for Supervised Learning:\\n\\n**Se...     2    8bb61997   \n",
       "c472f10d  5e97933310f217  markdown  # Regularization-2\\n\\n   ## 1. Ridge Regression\\n\\n<a ><img src=\"https://i.ibb.co/y4SJq5k/Screenshot-2021-07-14-at-2...    20    8bb61997   \n",
       "8515c21d  5e97933310f217  markdown  <a id =\"1\"></a> \\n# **Four Categories of Machine Learning** \\n\\n    \\n \\n1. Supervised Learning\\n2. Unsupervised Lea...     1    8bb61997   \n",
       "d72d0507  5e97933310f217  markdown  <a id =\"unsuper\"></a>\\n\\n# **2. Unsupervised Learning**\\n\\n    \"Unsupervised Learning is the bread and butter of dat...     3    8bb61997   \n",
       "9c617cba  5e97933310f217  markdown  # Leaky Relu\\n\\n>  **Leaky Rectified Linear Unit**, or Leaky ReLU, is a type of activation function based on a ReLU,...    27    8bb61997   \n",
       "dbbfaf24  5e97933310f217      code  num_validation_samples = 20000\\n\\nnp.random.shuffle(data)\\n\\n#Defining the validatian set.\\nvalidation_data= data[:n...     7    8bb61997   \n",
       "f907fbe0  5e97933310f217  markdown  #   **BATCH SIZE**\\n\\n>     Number of the samples that will be passed through to the network at one time.\\n\\n<a ><im...    21    8bb61997   \n",
       "2708c4b8  5e97933310f217  markdown                   <a id =\"kfo\"></a>\\n# 2. K-fold Validation\\n\\n    When we have too few samples for hold-out validation.     8    8bb61997   \n",
       "4a807ba9  5e97933310f217  markdown  <a id =\"zp\"></a>\\n\\n# <p style=\"color:green;font-size:25px \" >Zero Padding </p> \\n\\n\\n<a ><img src=\"https://i.ibb.co...    16    8bb61997   \n",
       "5408a3e6  5e97933310f217  markdown                                                                                     # **Sequential or Functional Model**    25    8bb61997   \n",
       "8c358a5c  5e97933310f217  markdown                                                        ![image.png](attachment:c0b9f51e-2abb-4960-bde7-bfabddee8f6e.png)    29    8bb61997   \n",
       "f98ac2d0  5e97933310f217  markdown  <a id =\"reg1\"></a>\\n\\n# <p style=\"color:purple;font-size:30px \">Regularization-1 </p> Regularization techniques are ...    13    8bb61997   \n",
       "c926405c  5e97933310f217  markdown  <a id =\"3\"></a>\\n<p style=\"color:blue;font-size:20px \" >Three classic evalution model: </p> \\n\\n# EVALUTATION RECIPE...     6    8bb61997   \n",
       "f87d78d5  5e97933310f217  markdown  # <p style=\"color:green;font-size:25px \" >Max Pooling  </p> <a ><img src=\"https://i.ibb.co/5Lzy1r1/Screenshot-from-2...    17    8bb61997   \n",
       "6934a531  5e97933310f217  markdown                   <a id =\"it\"></a>\\n\\n# 3. Iterated K-fold\\n\\n    We can evaluate our model \"as precisely as possible\".     10    8bb61997   \n",
       "96b20353  5e97933310f217      code  k = 4 #or 3,5..\\nnum_validation_samples = len(data)//k\\n\\nnp.random.shuffle(data)\\n\\nvalidation_scores = []\\n\\nfor f...     9    8bb61997   \n",
       "553f5b96  5e97933310f217  markdown  <a id =\"selfsup\"></a>\\n\\n# **3. Self-supervised Learning**\\n\\n    \"It is a supervised learning but without human-ann...     4    8bb61997   \n",
       "ce5cffa9  5e97933310f217  markdown  # <p style=\"color:blue;font-size:25px \" >HyperParameter </p> A hyperparameter is a parameter of a learning algorithm...    14    8bb61997   \n",
       "baa9655a  5e97933310f217  markdown  **There are two ways to build Keras models: sequential and functional.**\\n \\nThe sequential API allows you to create...    26    8bb61997   \n",
       "73ff316f  5e97933310f217  markdown  <a id =\"lr\"></a>\\n\\n# <p style=\"color:blue;font-size:25px \" >Learning Rate </p> Learning Rate symbolizes the step we...    15    8bb61997   \n",
       "f5d41cbd  5e97933310f217  markdown                                                                                                  # DATA AUGEMENTATION \\n    23    8bb61997   \n",
       "d8430e33  5e97933310f217  markdown  # Fine-tuning\\n    If it has learned the knowledge of recognizing cars, it can also notice trucks later. This is cal...    22    8bb61997   \n",
       "eb2b787d  5e97933310f217  markdown  <a id =\"RL\"></a>\\n\\n# **4. Reinforcement Learning**\\n\\n![image.png](attachment:7db13489-ac8a-488a-a4d4-b1502a93feba....     5    8bb61997   \n",
       "73da14f7  5e97933310f217      code  import numpy as np\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import Stratif...    11    8bb61997   \n",
       "8c9220b5  5e97933310f217  markdown  <a id =\"not\"></a>\\n\\n# <p style=\"color:red;font-size:20px \" >NOTES: </p> \\n\\n> 1. No information regarding the test ...    12    8bb61997   \n",
       "95ec6c68  5e97933310f217  markdown  \\nSources: \\n\\n[1] Yakup Genç, GTU Derin Öğrenme Ders Notları\\n\\n[2] Cristina Scheau, Regularization in deep learnin...    30    8bb61997   \n",
       "202615e2  5e97933310f217      code  #DATA AUGEMENTATION \\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport os\\nimport random\\nimport tensorfl...    24    8bb61997   \n",
       "\n",
       "         parent_id  pct_rank     label      pred  \n",
       "cell_id                                           \n",
       "1b79d054       NaN  0.612903  0.612903 -0.002829  \n",
       "2d7d9227       NaN  0.903226  0.903226 -0.001178  \n",
       "9f5e2233       NaN  0.580645  0.580645  0.011536  \n",
       "46fa93e3       NaN  0.000000  0.000000  0.028564  \n",
       "b0ea29f4       NaN  0.064516  0.064516  0.054230  \n",
       "c472f10d       NaN  0.645161  0.645161  0.057678  \n",
       "8515c21d       NaN  0.032258  0.032258  0.058167  \n",
       "d72d0507       NaN  0.096774  0.096774  0.141968  \n",
       "9c617cba       NaN  0.870968  0.870968  0.226196  \n",
       "dbbfaf24       NaN  0.225806  0.225806  0.225806  \n",
       "f907fbe0       NaN  0.677419  0.677419  0.264404  \n",
       "2708c4b8       NaN  0.258065  0.258065  0.348389  \n",
       "4a807ba9       NaN  0.516129  0.516129  0.408936  \n",
       "5408a3e6       NaN  0.806452  0.806452  0.414551  \n",
       "8c358a5c       NaN  0.935484  0.935484  0.415527  \n",
       "f98ac2d0       NaN  0.419355  0.419355  0.422363  \n",
       "c926405c       NaN  0.193548  0.193548  0.432617  \n",
       "f87d78d5       NaN  0.548387  0.548387  0.461426  \n",
       "6934a531       NaN  0.322581  0.322581  0.468750  \n",
       "96b20353       NaN  0.290323  0.290323  0.290323  \n",
       "553f5b96       NaN  0.129032  0.129032  0.531250  \n",
       "ce5cffa9       NaN  0.451613  0.451613  0.538086  \n",
       "baa9655a       NaN  0.838710  0.838710  0.556152  \n",
       "73ff316f       NaN  0.483871  0.483871  0.562500  \n",
       "f5d41cbd       NaN  0.741935  0.741935  0.604004  \n",
       "d8430e33       NaN  0.709677  0.709677  0.624512  \n",
       "eb2b787d       NaN  0.161290  0.161290  0.630859  \n",
       "73da14f7       NaN  0.354839  0.354839  0.354839  \n",
       "8c9220b5       NaN  0.387097  0.387097  0.811523  \n",
       "95ec6c68       NaN  0.967742  0.967742  0.950684  \n",
       "202615e2       NaN  0.774194  0.774194  0.774194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                       56a364c9726435\n",
      "label_order      [d1824dcf, 232912f8, ddfe5a63, 71945f79, 7cd943a6, 2b918080, c2978663]\n",
      "pred_order       [2b918080, 232912f8, ddfe5a63, 71945f79, 7cd943a6, d1824dcf, c2978663]\n",
      "kendall_score                                                                  0.142857\n",
      "Name: 3635, dtype: object\n",
      ">>> ---------- Notebook id: 56a364c9726435 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2b918080</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>markdown</td>\n",
       "      <td>This is Global Coronavirus (COVID-19) data, provided by Johns Hopkins and cleaned and reshaped with Tableau.Here I a...</td>\n",
       "      <td>5</td>\n",
       "      <td>af2210ef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>-0.001391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232912f8</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![](https://storage.googleapis.com/kagglesdsdata/datasets/623593/1112109/USA.jpg?GoogleAccessId=web-data@kaggle-1616...</td>\n",
       "      <td>1</td>\n",
       "      <td>af2210ef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddfe5a63</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Coronavirus is a family of viruses that can cause illness, which can vary from common cold and cough to sometimes mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>af2210ef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.220581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71945f79</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Data Source : https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases</td>\n",
       "      <td>3</td>\n",
       "      <td>af2210ef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.273682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cd943a6</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Tableau Dashboard</td>\n",
       "      <td>4</td>\n",
       "      <td>af2210ef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.683105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1824dcf</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>markdown</td>\n",
       "      <td>If you like this kernel Greatly Appreciate with UPVOTE.Thank you\\nhttps://public.tableau.com/profile/mahi.khedkar#!/...</td>\n",
       "      <td>0</td>\n",
       "      <td>af2210ef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2978663</th>\n",
       "      <td>56a364c9726435</td>\n",
       "      <td>code</td>\n",
       "      <td>#Import section\\n\\nfrom IPython.display import IFrame\\nIFrame('https://public.tableau.com/views/CoronavirusDashboard...</td>\n",
       "      <td>6</td>\n",
       "      <td>af2210ef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "2b918080  56a364c9726435  markdown  This is Global Coronavirus (COVID-19) data, provided by Johns Hopkins and cleaned and reshaped with Tableau.Here I a...     5    af2210ef   \n",
       "232912f8  56a364c9726435  markdown  ![](https://storage.googleapis.com/kagglesdsdata/datasets/623593/1112109/USA.jpg?GoogleAccessId=web-data@kaggle-1616...     1    af2210ef   \n",
       "ddfe5a63  56a364c9726435  markdown  Coronavirus is a family of viruses that can cause illness, which can vary from common cold and cough to sometimes mo...     2    af2210ef   \n",
       "71945f79  56a364c9726435  markdown                                         Data Source : https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases     3    af2210ef   \n",
       "7cd943a6  56a364c9726435  markdown                                                                                                        Tableau Dashboard     4    af2210ef   \n",
       "d1824dcf  56a364c9726435  markdown  If you like this kernel Greatly Appreciate with UPVOTE.Thank you\\nhttps://public.tableau.com/profile/mahi.khedkar#!/...     0    af2210ef   \n",
       "c2978663  56a364c9726435      code  #Import section\\n\\nfrom IPython.display import IFrame\\nIFrame('https://public.tableau.com/views/CoronavirusDashboard...     6    af2210ef   \n",
       "\n",
       "         parent_id  pct_rank     label      pred  \n",
       "cell_id                                           \n",
       "2b918080       NaN  0.714286  0.714286 -0.001391  \n",
       "232912f8       NaN  0.142857  0.142857  0.142212  \n",
       "ddfe5a63       NaN  0.285714  0.285714  0.220581  \n",
       "71945f79       NaN  0.428571  0.428571  0.273682  \n",
       "7cd943a6       NaN  0.571429  0.571429  0.683105  \n",
       "d1824dcf       NaN  0.000000  0.000000  0.908203  \n",
       "c2978663       NaN  0.857143  0.857143  0.857143  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                                                                        d127172adeacea\n",
      "label_order      [eebc3086, 722cf377, b37481da, 712782ed, 1afd3599, 0315d35b, e92fec1b, ceb68917, b53f604a, 01514c28, 5ad53400, c2a6e...\n",
      "pred_order       [eebc3086, 712782ed, 5ad53400, 722cf377, b53f604a, e92fec1b, c2a6e274, 01514c28, 1afd3599, ceb68917, 0315d35b, 56f0a...\n",
      "kendall_score                                                                                                                   0.179487\n",
      "Name: 8650, dtype: object\n",
      ">>> ---------- Notebook id: d127172adeacea ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eebc3086</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>This text is an English version of the following article written in Japanese in December 2019.\\n\\nhttps://qiita.com/...</td>\n",
       "      <td>0</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712782ed</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Explanation\\n\\nLet's look at points of the cells above!</td>\n",
       "      <td>3</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.298828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5ad53400</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Constants\\n\\n```python\\nSEED = 2019\\nN_FOLDS = 10\\n```\\n\\nIn advance, fix the seed of pseudo-random number (`SEED...</td>\n",
       "      <td>10</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.316895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722cf377</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td># This is \"one cell\"...\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b53f604a</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Preprocessing\\n\\n```python\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.preprocessing import StandardS...</td>\n",
       "      <td>8</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.396240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e92fec1b</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Data\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\npd.set_option('display.max_columns', None)\\n```\\n\\nTh...</td>\n",
       "      <td>6</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.418213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2a6e274</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Output list of file names given as input\\n\\n```python\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/i...</td>\n",
       "      <td>11</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.430908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01514c28</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Cross validation\\n\\n```python\\nfrom sklearn.model_selection import StratifiedKFold \\n```\\n\\nCross validation is n...</td>\n",
       "      <td>9</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.544922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1afd3599</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Display\\n\\n```python\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_inter...</td>\n",
       "      <td>4</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.553223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceb68917</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Visualization\\n\\n```python\\nimport pandas_profiling as pdp\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n...</td>\n",
       "      <td>7</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.566895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0315d35b</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Useful\\n\\n```python\\nimport tqdm\\nimport warnings\\nwarnings.simplefilter('ignore')\\n```\\n\\nIn data analysis, ther...</td>\n",
       "      <td>5</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.577148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56f0af7a</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>markdown</td>\n",
       "      <td>\\n# Conclusion\\n\\nIf you have any ideas or advice, please let me know!</td>\n",
       "      <td>12</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.918945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b37481da</th>\n",
       "      <td>d127172adeacea</td>\n",
       "      <td>code</td>\n",
       "      <td># Display\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_interactivity = \"al...</td>\n",
       "      <td>2</td>\n",
       "      <td>aed848ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "eebc3086  d127172adeacea  markdown  This text is an English version of the following article written in Japanese in December 2019.\\n\\nhttps://qiita.com/...     0    aed848ca   \n",
       "712782ed  d127172adeacea  markdown                                                                # Explanation\\n\\nLet's look at points of the cells above!     3    aed848ca   \n",
       "5ad53400  d127172adeacea  markdown  ## Constants\\n\\n```python\\nSEED = 2019\\nN_FOLDS = 10\\n```\\n\\nIn advance, fix the seed of pseudo-random number (`SEED...    10    aed848ca   \n",
       "722cf377  d127172adeacea  markdown                                                                                                # This is \"one cell\"...\\n     1    aed848ca   \n",
       "b53f604a  d127172adeacea  markdown  ## Preprocessing\\n\\n```python\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.preprocessing import StandardS...     8    aed848ca   \n",
       "e92fec1b  d127172adeacea  markdown  ## Data\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\npd.set_option('display.max_columns', None)\\n```\\n\\nTh...     6    aed848ca   \n",
       "c2a6e274  d127172adeacea  markdown  ## Output list of file names given as input\\n\\n```python\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/i...    11    aed848ca   \n",
       "01514c28  d127172adeacea  markdown  ## Cross validation\\n\\n```python\\nfrom sklearn.model_selection import StratifiedKFold \\n```\\n\\nCross validation is n...     9    aed848ca   \n",
       "1afd3599  d127172adeacea  markdown  ## Display\\n\\n```python\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_inter...     4    aed848ca   \n",
       "ceb68917  d127172adeacea  markdown  ## Visualization\\n\\n```python\\nimport pandas_profiling as pdp\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n...     7    aed848ca   \n",
       "0315d35b  d127172adeacea  markdown  ## Useful\\n\\n```python\\nimport tqdm\\nimport warnings\\nwarnings.simplefilter('ignore')\\n```\\n\\nIn data analysis, ther...     5    aed848ca   \n",
       "56f0af7a  d127172adeacea  markdown                                                   \\n# Conclusion\\n\\nIf you have any ideas or advice, please let me know!    12    aed848ca   \n",
       "b37481da  d127172adeacea      code  # Display\\nfrom IPython.core.interactiveshell import InteractiveShell\\nInteractiveShell.ast_node_interactivity = \"al...     2    aed848ca   \n",
       "\n",
       "         parent_id  pct_rank     label      pred  \n",
       "cell_id                                           \n",
       "eebc3086       NaN  0.000000  0.000000 -0.002520  \n",
       "712782ed       NaN  0.230769  0.230769  0.298828  \n",
       "5ad53400       NaN  0.769231  0.769231  0.316895  \n",
       "722cf377       NaN  0.076923  0.076923  0.375000  \n",
       "b53f604a       NaN  0.615385  0.615385  0.396240  \n",
       "e92fec1b       NaN  0.461538  0.461538  0.418213  \n",
       "c2a6e274       NaN  0.846154  0.846154  0.430908  \n",
       "01514c28       NaN  0.692308  0.692308  0.544922  \n",
       "1afd3599       NaN  0.307692  0.307692  0.553223  \n",
       "ceb68917       NaN  0.538462  0.538462  0.566895  \n",
       "0315d35b       NaN  0.384615  0.384615  0.577148  \n",
       "56f0af7a       NaN  0.923077  0.923077  0.918945  \n",
       "b37481da       NaN  0.153846  0.153846  0.153846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                   4a99d2ffd04cd6\n",
      "label_order      [19bb0372, 782c7b9e, 5b019082, 067348b8, 531994ce]\n",
      "pred_order       [531994ce, 19bb0372, 782c7b9e, 5b019082, 067348b8]\n",
      "kendall_score                                                   0.2\n",
      "Name: 3093, dtype: object\n",
      ">>> ---------- Notebook id: 4a99d2ffd04cd6 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>531994ce</th>\n",
       "      <td>4a99d2ffd04cd6</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Credits: Python Engineer\\n\\nDon't hesitate to watch YouTube video. It has clear explanation\\n\\nhttps://youtu.be/3Kb0...</td>\n",
       "      <td>4</td>\n",
       "      <td>9ef2154d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19bb0372</th>\n",
       "      <td>4a99d2ffd04cd6</td>\n",
       "      <td>code</td>\n",
       "      <td>import torch\\n\\n\\n# Intialize values to X,Y\\n\\n\\nx = torch.tensor(1.0)\\ny = torch.tensor(2.0)</td>\n",
       "      <td>0</td>\n",
       "      <td>9ef2154d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782c7b9e</th>\n",
       "      <td>4a99d2ffd04cd6</td>\n",
       "      <td>code</td>\n",
       "      <td>\\n# This is the parameter we want to optimize -&gt; requires_grad=True\\nw = torch.tensor(1.0, requires_grad=True)\\n\\n# ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9ef2154d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5b019082</th>\n",
       "      <td>4a99d2ffd04cd6</td>\n",
       "      <td>code</td>\n",
       "      <td>\\n\\n# backward pass to compute gradient dLoss/dw\\nloss.backward()\\nprint(w.grad)</td>\n",
       "      <td>2</td>\n",
       "      <td>9ef2154d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>067348b8</th>\n",
       "      <td>4a99d2ffd04cd6</td>\n",
       "      <td>code</td>\n",
       "      <td>\\n\\n# update weights\\n# next forward and backward pass...\\n\\n# continue optimizing:\\n# update weights, this operatio...</td>\n",
       "      <td>3</td>\n",
       "      <td>9ef2154d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "531994ce  4a99d2ffd04cd6  markdown  Credits: Python Engineer\\n\\nDon't hesitate to watch YouTube video. It has clear explanation\\n\\nhttps://youtu.be/3Kb0...     4    9ef2154d   \n",
       "19bb0372  4a99d2ffd04cd6      code                            import torch\\n\\n\\n# Intialize values to X,Y\\n\\n\\nx = torch.tensor(1.0)\\ny = torch.tensor(2.0)     0    9ef2154d   \n",
       "782c7b9e  4a99d2ffd04cd6      code  \\n# This is the parameter we want to optimize -> requires_grad=True\\nw = torch.tensor(1.0, requires_grad=True)\\n\\n# ...     1    9ef2154d   \n",
       "5b019082  4a99d2ffd04cd6      code                                         \\n\\n# backward pass to compute gradient dLoss/dw\\nloss.backward()\\nprint(w.grad)     2    9ef2154d   \n",
       "067348b8  4a99d2ffd04cd6      code  \\n\\n# update weights\\n# next forward and backward pass...\\n\\n# continue optimizing:\\n# update weights, this operatio...     3    9ef2154d   \n",
       "\n",
       "         parent_id  pct_rank  label      pred  \n",
       "cell_id                                        \n",
       "531994ce       NaN       0.8    0.8 -0.001771  \n",
       "19bb0372       NaN       0.0    0.0  0.000000  \n",
       "782c7b9e       NaN       0.2    0.2  0.200000  \n",
       "5b019082       NaN       0.4    0.4  0.400000  \n",
       "067348b8       NaN       0.6    0.6  0.600000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                                                                        206aadfedae1ad\n",
      "label_order      [46946ca5, 022d6bd1, 3a917eba, 59da069c, 4d9f8b9f, eb012803, d4470b3c, 6296022f, 2ba8a5bf, 86943f9e, 9927ec8f, 37578...\n",
      "pred_order       [46946ca5, 59da069c, 77022ccd, a2422444, 7d3549e7, 55790065, 1e7ecfb4, eb012803, 3ec5ab6f, 3757841d, 1e6707b1, 022d6...\n",
      "kendall_score                                                                                                                   0.219873\n",
      "Name: 1353, dtype: object\n",
      ">>> ---------- Notebook id: 206aadfedae1ad ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46946ca5</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 7 Coolest Python Packages Top Kagglers Are Using Without Telling You\\n## Let me expose the secrets...\\n![](https:/...</td>\n",
       "      <td>0</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59da069c</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Kaggle is a hot spot for what is trending in data science and machine learning.\\n\\nDue to its competitiveness, the t...</td>\n",
       "      <td>3</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.005646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77022ccd</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>The available tools and packages to execute data science tasks are endless. Everyone has the right to be overwhelmed...</td>\n",
       "      <td>42</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.017120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2422444</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Explainable AI (XAI) is one of the strongest trends in the ML and AI sphere. Companies and businesses are starting t...</td>\n",
       "      <td>32</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.018707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d3549e7</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Normally, I am against any library or tool that takes a programmer away from writing actual code. But, since auto-ED...</td>\n",
       "      <td>40</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.028137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55790065</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Lazypredict is one of the best one-liner packages I have ever seen.\\n\\nUsing the library, you can train almost all S...</td>\n",
       "      <td>20</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.028152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e7ecfb4</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>### 🛠 GitHub and documentation\\n- https://github.com/h2oai/datatable\\n- https://datatable.readthedocs.io/en/latest/?...</td>\n",
       "      <td>13</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.028641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb012803</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![](https://cdn-images-1.medium.com/max/800/1*1sUCX4FKCLjJzbEqMjg2YQ.png)\\n&lt;figcaption style=\"text-align: center;\"&gt;\\...</td>\n",
       "      <td>5</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.041168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ec5ab6f</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![](https://cdn-images-1.medium.com/max/800/1*ZoH5jGuQiKKhxeZYNHcwDA.png)</td>\n",
       "      <td>36</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.064270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757841d</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![](https://cdn-images-1.medium.com/max/800/1*HfCFXaFA0cS2uLw1Gv3x9w.png)</td>\n",
       "      <td>11</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.068115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e6707b1</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>```python\\nfrom lazypredict.Supervised import (  # pip install lazypredict\\n    LazyClassifier,\\n    LazyRegressor,\\...</td>\n",
       "      <td>21</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.101746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>022d6bd1</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Setup</td>\n",
       "      <td>1</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.114136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9711e76b</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>As dataset sizes are getting bigger, people are paying more attention to out-of-memory, multi-threaded data preproce...</td>\n",
       "      <td>12</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.117126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090dad6</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Here are my latest viral hits...\\n- [20 Burning XGBoost FAQs Answered to Use the Library Like a Pro](https://towa...</td>\n",
       "      <td>43</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.141724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a917eba</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport optuna\\nimport pandas as pd\\nimport s...</td>\n",
       "      <td>2</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a5e01ae</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![image.png](attachment:41542a5f-77e6-4b56-8898-9f8cbc519658.png)</td>\n",
       "      <td>22</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.178833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97365999</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>If you thought GPUs are deep learning-exclusive, you are *horribly* mistaken.\\n\\nThe cuDF library, created by the op...</td>\n",
       "      <td>37</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.204712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9927ec8f</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 2. Datatable</td>\n",
       "      <td>10</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.212891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296022f</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>When I look at plots like these, they remind me of why I got into data science in the first place - data is beautifu...</td>\n",
       "      <td>7</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.234741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeeaedd5</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>The main data structure in `datatable` is `Frame` (as in DataFrame).</td>\n",
       "      <td>14</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.256348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d9f8b9f</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 1. UMAP</td>\n",
       "      <td>4</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.276855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6fc8be3a</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>code</td>\n",
       "      <td>import datatable as dt  # pip install datatable\\n\\nframe = dt.fread(\"https://raw.githubusercontent.com/BexTuychiev/m...</td>\n",
       "      <td>15</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.340909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2cb7aec2</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![](https://miro.medium.com/max/1400/0*IBkpkOCS0anhUHWp.png)</td>\n",
       "      <td>25</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.337646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111865b0</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 7. Automatic EDA libraries</td>\n",
       "      <td>39</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.423096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70757f2c</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>A simple GroupBy operation:</td>\n",
       "      <td>17</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.424805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72d107df</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>code</td>\n",
       "      <td>type(frame)</td>\n",
       "      <td>16</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b393e2c0</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>```python\\nimport cudf, io, requests\\nfrom io import StringIO\\n\\nurl = \"https://github.com/plotly/datasets/raw/maste...</td>\n",
       "      <td>38</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4470b3c</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Above is a 100k row dataset with 75 features projected to 2D using a package called UMAP. Each dot represents a sing...</td>\n",
       "      <td>6</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.482666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929af8fc</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>code</td>\n",
       "      <td>from datatable import by, f, sum\\n\\ntips = sns.load_dataset(\"tips\")\\nframe = dt.Frame(tips)\\nframe[:, sum(f.total_bi...</td>\n",
       "      <td>18</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc7b5bf8</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>One of the more recent libraries I have added to my skill-stack is Kagglers' favorite - Optuna. \\n\\nOptuna is a next...</td>\n",
       "      <td>26</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.577148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e67db544</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>An insight like this will free you from the manual task of selecting a base model, a time much better spent on tasks...</td>\n",
       "      <td>23</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.579590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72a225e4</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 6. Rapids cuDF</td>\n",
       "      <td>35</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.587891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693056e</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>For the sake of simplicity, we are trying to optimize the function $(x - 1)^2 + (y + 3)^2$. As you can see, the tune...</td>\n",
       "      <td>29</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.607422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642bdf43</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 4. Optuna</td>\n",
       "      <td>24</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.613281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5cd6fe97</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 3. Lazypredict</td>\n",
       "      <td>19</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.618652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6df28361</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>code</td>\n",
       "      <td>import optuna  # pip install optuna\\n\\n\\ndef objective(trial):\\n    x = trial.suggest_float(\"x\", -7, 7)\\n    y = tri...</td>\n",
       "      <td>27</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ba8a5bf</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>```python\\nimport umap  # pip install umap-learn\\n\\n# Create the mapper\\nmapper = umap.UMAP()\\n# Fit to the data\\nma...</td>\n",
       "      <td>8</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.732910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86943f9e</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>The most important parameters of `UMAP` estimator are `n_neighbors` and `min_dist` (minimum distance). Think of `n_n...</td>\n",
       "      <td>9</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.822754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b56ae110</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td># 5. SHAP</td>\n",
       "      <td>30</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.847656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218d464</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>code</td>\n",
       "      <td>study.best_value</td>\n",
       "      <td>28</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b9adfe6</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>![](https://shap.readthedocs.io/en/latest/_images/shap_header.png)</td>\n",
       "      <td>31</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.874512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d61fd548</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Summary</td>\n",
       "      <td>41</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.909180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889eee9c</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Trust me, SHAP has way cooler plots. It is such a powerful tool that the Kaggle platform has an [entire free course]...</td>\n",
       "      <td>33</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.952148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944bba15</th>\n",
       "      <td>206aadfedae1ad</td>\n",
       "      <td>code</td>\n",
       "      <td>import shap  # pip install shap\\nimport xgboost as xgb\\n\\n# Load and train a model\\nX, y = shap.datasets.diabetes()\\...</td>\n",
       "      <td>34</td>\n",
       "      <td>54b0f8b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "46946ca5  206aadfedae1ad  markdown  # 7 Coolest Python Packages Top Kagglers Are Using Without Telling You\\n## Let me expose the secrets...\\n![](https:/...     0    54b0f8b3   \n",
       "59da069c  206aadfedae1ad  markdown  Kaggle is a hot spot for what is trending in data science and machine learning.\\n\\nDue to its competitiveness, the t...     3    54b0f8b3   \n",
       "77022ccd  206aadfedae1ad  markdown  The available tools and packages to execute data science tasks are endless. Everyone has the right to be overwhelmed...    42    54b0f8b3   \n",
       "a2422444  206aadfedae1ad  markdown  Explainable AI (XAI) is one of the strongest trends in the ML and AI sphere. Companies and businesses are starting t...    32    54b0f8b3   \n",
       "7d3549e7  206aadfedae1ad  markdown  Normally, I am against any library or tool that takes a programmer away from writing actual code. But, since auto-ED...    40    54b0f8b3   \n",
       "55790065  206aadfedae1ad  markdown  Lazypredict is one of the best one-liner packages I have ever seen.\\n\\nUsing the library, you can train almost all S...    20    54b0f8b3   \n",
       "1e7ecfb4  206aadfedae1ad  markdown  ### 🛠 GitHub and documentation\\n- https://github.com/h2oai/datatable\\n- https://datatable.readthedocs.io/en/latest/?...    13    54b0f8b3   \n",
       "eb012803  206aadfedae1ad  markdown  ![](https://cdn-images-1.medium.com/max/800/1*1sUCX4FKCLjJzbEqMjg2YQ.png)\\n<figcaption style=\"text-align: center;\">\\...     5    54b0f8b3   \n",
       "3ec5ab6f  206aadfedae1ad  markdown                                                ![](https://cdn-images-1.medium.com/max/800/1*ZoH5jGuQiKKhxeZYNHcwDA.png)    36    54b0f8b3   \n",
       "3757841d  206aadfedae1ad  markdown                                                ![](https://cdn-images-1.medium.com/max/800/1*HfCFXaFA0cS2uLw1Gv3x9w.png)    11    54b0f8b3   \n",
       "1e6707b1  206aadfedae1ad  markdown  ```python\\nfrom lazypredict.Supervised import (  # pip install lazypredict\\n    LazyClassifier,\\n    LazyRegressor,\\...    21    54b0f8b3   \n",
       "022d6bd1  206aadfedae1ad  markdown                                                                                                                 ## Setup     1    54b0f8b3   \n",
       "9711e76b  206aadfedae1ad  markdown  As dataset sizes are getting bigger, people are paying more attention to out-of-memory, multi-threaded data preproce...    12    54b0f8b3   \n",
       "7090dad6  206aadfedae1ad  markdown  ## Here are my latest viral hits...\\n- [20 Burning XGBoost FAQs Answered to Use the Library Like a Pro](https://towa...    43    54b0f8b3   \n",
       "3a917eba  206aadfedae1ad      code  import warnings\\n\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport optuna\\nimport pandas as pd\\nimport s...     2    54b0f8b3   \n",
       "4a5e01ae  206aadfedae1ad  markdown                                                        ![image.png](attachment:41542a5f-77e6-4b56-8898-9f8cbc519658.png)    22    54b0f8b3   \n",
       "97365999  206aadfedae1ad  markdown  If you thought GPUs are deep learning-exclusive, you are *horribly* mistaken.\\n\\nThe cuDF library, created by the op...    37    54b0f8b3   \n",
       "9927ec8f  206aadfedae1ad  markdown                                                                                                           # 2. Datatable    10    54b0f8b3   \n",
       "6296022f  206aadfedae1ad  markdown  When I look at plots like these, they remind me of why I got into data science in the first place - data is beautifu...     7    54b0f8b3   \n",
       "aeeaedd5  206aadfedae1ad  markdown                                                    The main data structure in `datatable` is `Frame` (as in DataFrame).     14    54b0f8b3   \n",
       "4d9f8b9f  206aadfedae1ad  markdown                                                                                                                # 1. UMAP     4    54b0f8b3   \n",
       "6fc8be3a  206aadfedae1ad      code  import datatable as dt  # pip install datatable\\n\\nframe = dt.fread(\"https://raw.githubusercontent.com/BexTuychiev/m...    15    54b0f8b3   \n",
       "2cb7aec2  206aadfedae1ad  markdown                                                             ![](https://miro.medium.com/max/1400/0*IBkpkOCS0anhUHWp.png)    25    54b0f8b3   \n",
       "111865b0  206aadfedae1ad  markdown                                                                                             # 7. Automatic EDA libraries    39    54b0f8b3   \n",
       "70757f2c  206aadfedae1ad  markdown                                                                                              A simple GroupBy operation:    17    54b0f8b3   \n",
       "72d107df  206aadfedae1ad      code                                                                                                              type(frame)    16    54b0f8b3   \n",
       "b393e2c0  206aadfedae1ad  markdown  ```python\\nimport cudf, io, requests\\nfrom io import StringIO\\n\\nurl = \"https://github.com/plotly/datasets/raw/maste...    38    54b0f8b3   \n",
       "d4470b3c  206aadfedae1ad  markdown  Above is a 100k row dataset with 75 features projected to 2D using a package called UMAP. Each dot represents a sing...     6    54b0f8b3   \n",
       "929af8fc  206aadfedae1ad      code  from datatable import by, f, sum\\n\\ntips = sns.load_dataset(\"tips\")\\nframe = dt.Frame(tips)\\nframe[:, sum(f.total_bi...    18    54b0f8b3   \n",
       "fc7b5bf8  206aadfedae1ad  markdown  One of the more recent libraries I have added to my skill-stack is Kagglers' favorite - Optuna. \\n\\nOptuna is a next...    26    54b0f8b3   \n",
       "e67db544  206aadfedae1ad  markdown  An insight like this will free you from the manual task of selecting a base model, a time much better spent on tasks...    23    54b0f8b3   \n",
       "72a225e4  206aadfedae1ad  markdown                                                                                                         # 6. Rapids cuDF    35    54b0f8b3   \n",
       "5693056e  206aadfedae1ad  markdown  For the sake of simplicity, we are trying to optimize the function $(x - 1)^2 + (y + 3)^2$. As you can see, the tune...    29    54b0f8b3   \n",
       "642bdf43  206aadfedae1ad  markdown                                                                                                              # 4. Optuna    24    54b0f8b3   \n",
       "5cd6fe97  206aadfedae1ad  markdown                                                                                                         # 3. Lazypredict    19    54b0f8b3   \n",
       "6df28361  206aadfedae1ad      code  import optuna  # pip install optuna\\n\\n\\ndef objective(trial):\\n    x = trial.suggest_float(\"x\", -7, 7)\\n    y = tri...    27    54b0f8b3   \n",
       "2ba8a5bf  206aadfedae1ad  markdown  ```python\\nimport umap  # pip install umap-learn\\n\\n# Create the mapper\\nmapper = umap.UMAP()\\n# Fit to the data\\nma...     8    54b0f8b3   \n",
       "86943f9e  206aadfedae1ad  markdown  The most important parameters of `UMAP` estimator are `n_neighbors` and `min_dist` (minimum distance). Think of `n_n...     9    54b0f8b3   \n",
       "b56ae110  206aadfedae1ad  markdown                                                                                                                # 5. SHAP    30    54b0f8b3   \n",
       "1218d464  206aadfedae1ad      code                                                                                                         study.best_value    28    54b0f8b3   \n",
       "2b9adfe6  206aadfedae1ad  markdown                                                       ![](https://shap.readthedocs.io/en/latest/_images/shap_header.png)    31    54b0f8b3   \n",
       "d61fd548  206aadfedae1ad  markdown                                                                                                               ## Summary    41    54b0f8b3   \n",
       "889eee9c  206aadfedae1ad  markdown  Trust me, SHAP has way cooler plots. It is such a powerful tool that the Kaggle platform has an [entire free course]...    33    54b0f8b3   \n",
       "944bba15  206aadfedae1ad      code  import shap  # pip install shap\\nimport xgboost as xgb\\n\\n# Load and train a model\\nX, y = shap.datasets.diabetes()\\...    34    54b0f8b3   \n",
       "\n",
       "         parent_id  pct_rank     label      pred  \n",
       "cell_id                                           \n",
       "46946ca5       NaN  0.000000  0.000000 -0.001430  \n",
       "59da069c       NaN  0.068182  0.068182  0.005646  \n",
       "77022ccd       NaN  0.954545  0.954545  0.017120  \n",
       "a2422444       NaN  0.727273  0.727273  0.018707  \n",
       "7d3549e7       NaN  0.909091  0.909091  0.028137  \n",
       "55790065       NaN  0.454545  0.454545  0.028152  \n",
       "1e7ecfb4       NaN  0.295455  0.295455  0.028641  \n",
       "eb012803       NaN  0.113636  0.113636  0.041168  \n",
       "3ec5ab6f       NaN  0.818182  0.818182  0.064270  \n",
       "3757841d       NaN  0.250000  0.250000  0.068115  \n",
       "1e6707b1       NaN  0.477273  0.477273  0.101746  \n",
       "022d6bd1       NaN  0.022727  0.022727  0.114136  \n",
       "9711e76b       NaN  0.272727  0.272727  0.117126  \n",
       "7090dad6       NaN  0.977273  0.977273  0.141724  \n",
       "3a917eba       NaN  0.045455  0.045455  0.045455  \n",
       "4a5e01ae       NaN  0.500000  0.500000  0.178833  \n",
       "97365999       NaN  0.840909  0.840909  0.204712  \n",
       "9927ec8f       NaN  0.227273  0.227273  0.212891  \n",
       "6296022f       NaN  0.159091  0.159091  0.234741  \n",
       "aeeaedd5       NaN  0.318182  0.318182  0.256348  \n",
       "4d9f8b9f       NaN  0.090909  0.090909  0.276855  \n",
       "6fc8be3a       NaN  0.340909  0.340909  0.340909  \n",
       "2cb7aec2       NaN  0.568182  0.568182  0.337646  \n",
       "111865b0       NaN  0.886364  0.886364  0.423096  \n",
       "70757f2c       NaN  0.386364  0.386364  0.424805  \n",
       "72d107df       NaN  0.363636  0.363636  0.363636  \n",
       "b393e2c0       NaN  0.863636  0.863636  0.433594  \n",
       "d4470b3c       NaN  0.136364  0.136364  0.482666  \n",
       "929af8fc       NaN  0.409091  0.409091  0.409091  \n",
       "fc7b5bf8       NaN  0.590909  0.590909  0.577148  \n",
       "e67db544       NaN  0.522727  0.522727  0.579590  \n",
       "72a225e4       NaN  0.795455  0.795455  0.587891  \n",
       "5693056e       NaN  0.659091  0.659091  0.607422  \n",
       "642bdf43       NaN  0.545455  0.545455  0.613281  \n",
       "5cd6fe97       NaN  0.431818  0.431818  0.618652  \n",
       "6df28361       NaN  0.613636  0.613636  0.613636  \n",
       "2ba8a5bf       NaN  0.181818  0.181818  0.732910  \n",
       "86943f9e       NaN  0.204545  0.204545  0.822754  \n",
       "b56ae110       NaN  0.681818  0.681818  0.847656  \n",
       "1218d464       NaN  0.636364  0.636364  0.636364  \n",
       "2b9adfe6       NaN  0.704545  0.704545  0.874512  \n",
       "d61fd548       NaN  0.931818  0.931818  0.909180  \n",
       "889eee9c       NaN  0.750000  0.750000  0.952148  \n",
       "944bba15       NaN  0.772727  0.772727  0.772727  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "id                                                                                                                        17845073a429f3\n",
      "label_order      [502033a4, 794feada, a42f4b7e, b9d3bfc2, a706930b, 1441e3fc, ece1fb3b, d4e523f0, c6b9d271, 87794ae1, bc9d7947, 1e2a3...\n",
      "pred_order       [502033a4, d50e67bb, a42f4b7e, 205b4129, 7cc1fd2a, 68bcf209, 794feada, b9d3bfc2, a706930b, 1441e3fc, a6f2a408, d4e52...\n",
      "kendall_score                                                                                                                   0.224638\n",
      "Name: 984, dtype: object\n",
      ">>> ---------- Notebook id: 17845073a429f3 ----------\n",
      ">>> pred_order_col result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502033a4</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h1&gt; COVID-19 Analysis Notebook on Comorbidities (CANCe) &lt;/h1&gt;\\n\\n&lt;h2&gt; What is the incident of COVID-19 Infections i...</td>\n",
       "      <td>0</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d50e67bb</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;img src=\"https://www.statista.com/graphic/1/1102796/south-korea-covid-19-deaths-by-chronic-disease.jpg\" alt=\"Statis...</td>\n",
       "      <td>18</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.057007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a42f4b7e</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td># &lt;a id='main'&gt;&lt;h3&gt;Table of Contents&lt;/h3&gt;&lt;/a&gt;\\n- [Importing the Essential Libraries](#lib)\\n- [Datasets used in note...</td>\n",
       "      <td>2</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.057831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205b4129</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h3&gt; Breakdown of COVID-19 Death Cases in South Korea &lt;/h3&gt;\\n\\nThe following is the dataset that shows the deaths in...</td>\n",
       "      <td>17</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.095581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cc1fd2a</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;img src=\"https://www.statista.com/graphic/1/1110949/common-comorbidities-in-covid-19-deceased-patients-in-italy.jpg...</td>\n",
       "      <td>22</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.121704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68bcf209</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;img src=\"https://www.statista.com/graphic/1/1108836/china-coronavirus-covid-19-fatality-rate-by-health-condition.jp...</td>\n",
       "      <td>20</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.134521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794feada</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;H3&gt; Task Details &lt;/H3&gt;\\n\\nThe Roche Data Science Coalition is a group of like-minded public and private organizatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.145874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b9d3bfc2</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td># &lt;a id='lib'&gt;&lt;h3&gt;Importing the essential libraries&lt;/h3&gt;&lt;/a&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.155273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a706930b</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>code</td>\n",
       "      <td>#Data Analyses Libraries\\nimport pandas as pd                \\nimport numpy as np    \\nfrom urllib.request import ur...</td>\n",
       "      <td>4</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441e3fc</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td># &lt;a id='data'&gt;&lt;h3&gt;Datasets used for analyses in this notebook&lt;/h3&gt;&lt;/a&gt;\\n\\nThe various datasets that we take under c...</td>\n",
       "      <td>5</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.200073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a6f2a408</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;iframe src='https://flo.uri.sh/visualisation/2260261/embed' frameborder='0' scrolling='no' style='width:100%;height...</td>\n",
       "      <td>13</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.210571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4e523f0</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>The dataset contains information on the people admission to hospitals and the severity. The most severe ones were ad...</td>\n",
       "      <td>7</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.378662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f504d9dd</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h3&gt; Breakdown of COVID-19 Death Cases in Italy &lt;/h3&gt;\\n\\nFor the case of Italy **16.2%** of the total deaths due to ...</td>\n",
       "      <td>21</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.395996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ece1fb3b</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>code</td>\n",
       "      <td>#Importing the clinical spectrum data\\nclinical_spectrum = pd.read_csv('../input/uncover/UNCOVER/einstein/diagnosis-...</td>\n",
       "      <td>6</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20e7ebe2</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Verifying the Results : Cancer and COVID-19</td>\n",
       "      <td>16</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.402832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd8947db</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;H3&gt; Analysis of Electrolyte Abnormalities &lt;/h3&gt;\\n\\n\\n&lt;img src=\"https://i.ibb.co/gTjCb0X/4.png\" alt=\"4\" border=\"0\"&gt;\\...</td>\n",
       "      <td>15</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.492676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87794ae1</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h3&gt; Blending the datasets together to analyze positive and negative figures &lt;/h3&gt;</td>\n",
       "      <td>9</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.527832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a9d352d5</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h3&gt; Comorbidites of deaths in China because of COVID-19 &lt;/H3&gt;\\n\\nFor the case of China amongst the total deaths in ...</td>\n",
       "      <td>19</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.595703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c6b9d271</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>code</td>\n",
       "      <td>#Filetering the datasets\\npositive_condition = clinical_spectrum['sars_cov_2_exam_result'] == 'positive'\\npositive_c...</td>\n",
       "      <td>8</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e2a3b00</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h3&gt; Which are the most definitive clinical parameters that seperates poisitive and negative cases? &lt;/h3&gt;\\n\\nGiving ...</td>\n",
       "      <td>11</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.778809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc9d7947</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>code</td>\n",
       "      <td>#Making columns for the dataset\\npositive_mean = positive_mean.to_frame()\\npositive_mean = positive_mean.reset_index...</td>\n",
       "      <td>10</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c96f0973</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Further research needs to be incorporated on does anyone of this figures leads to Cancer or these clincal informatio...</td>\n",
       "      <td>14</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33db9540</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>&lt;h3&gt; The next big steps &lt;/h3&gt;\\n\\nWe analyzed and found out for roughly 17% of the deaths in COVID-19 Cancer plays a ...</td>\n",
       "      <td>23</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.984863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d6201e0</th>\n",
       "      <td>17845073a429f3</td>\n",
       "      <td>code</td>\n",
       "      <td>#The most important clinical factors\\npositive_mean['Change'] =  positive_mean['Positive_figures'] - positive_mean['...</td>\n",
       "      <td>12</td>\n",
       "      <td>fbae70fc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id cell_type                                                                                                                   source  rank ancestor_id  \\\n",
       "cell_id                                                                                                                                                                         \n",
       "502033a4  17845073a429f3  markdown  <h1> COVID-19 Analysis Notebook on Comorbidities (CANCe) </h1>\\n\\n<h2> What is the incident of COVID-19 Infections i...     0    fbae70fc   \n",
       "d50e67bb  17845073a429f3  markdown  <img src=\"https://www.statista.com/graphic/1/1102796/south-korea-covid-19-deaths-by-chronic-disease.jpg\" alt=\"Statis...    18    fbae70fc   \n",
       "a42f4b7e  17845073a429f3  markdown  # <a id='main'><h3>Table of Contents</h3></a>\\n- [Importing the Essential Libraries](#lib)\\n- [Datasets used in note...     2    fbae70fc   \n",
       "205b4129  17845073a429f3  markdown  <h3> Breakdown of COVID-19 Death Cases in South Korea </h3>\\n\\nThe following is the dataset that shows the deaths in...    17    fbae70fc   \n",
       "7cc1fd2a  17845073a429f3  markdown  <img src=\"https://www.statista.com/graphic/1/1110949/common-comorbidities-in-covid-19-deceased-patients-in-italy.jpg...    22    fbae70fc   \n",
       "68bcf209  17845073a429f3  markdown  <img src=\"https://www.statista.com/graphic/1/1108836/china-coronavirus-covid-19-fatality-rate-by-health-condition.jp...    20    fbae70fc   \n",
       "794feada  17845073a429f3  markdown  <H3> Task Details </H3>\\n\\nThe Roche Data Science Coalition is a group of like-minded public and private organizatio...     1    fbae70fc   \n",
       "b9d3bfc2  17845073a429f3  markdown                                                             # <a id='lib'><h3>Importing the essential libraries</h3></a>     3    fbae70fc   \n",
       "a706930b  17845073a429f3      code  #Data Analyses Libraries\\nimport pandas as pd                \\nimport numpy as np    \\nfrom urllib.request import ur...     4    fbae70fc   \n",
       "1441e3fc  17845073a429f3  markdown  # <a id='data'><h3>Datasets used for analyses in this notebook</h3></a>\\n\\nThe various datasets that we take under c...     5    fbae70fc   \n",
       "a6f2a408  17845073a429f3  markdown  <iframe src='https://flo.uri.sh/visualisation/2260261/embed' frameborder='0' scrolling='no' style='width:100%;height...    13    fbae70fc   \n",
       "d4e523f0  17845073a429f3  markdown  The dataset contains information on the people admission to hospitals and the severity. The most severe ones were ad...     7    fbae70fc   \n",
       "f504d9dd  17845073a429f3  markdown  <h3> Breakdown of COVID-19 Death Cases in Italy </h3>\\n\\nFor the case of Italy **16.2%** of the total deaths due to ...    21    fbae70fc   \n",
       "ece1fb3b  17845073a429f3      code  #Importing the clinical spectrum data\\nclinical_spectrum = pd.read_csv('../input/uncover/UNCOVER/einstein/diagnosis-...     6    fbae70fc   \n",
       "20e7ebe2  17845073a429f3  markdown                                                                            # Verifying the Results : Cancer and COVID-19    16    fbae70fc   \n",
       "cd8947db  17845073a429f3  markdown  <H3> Analysis of Electrolyte Abnormalities </h3>\\n\\n\\n<img src=\"https://i.ibb.co/gTjCb0X/4.png\" alt=\"4\" border=\"0\">\\...    15    fbae70fc   \n",
       "87794ae1  17845073a429f3  markdown                                       <h3> Blending the datasets together to analyze positive and negative figures </h3>     9    fbae70fc   \n",
       "a9d352d5  17845073a429f3  markdown  <h3> Comorbidites of deaths in China because of COVID-19 </H3>\\n\\nFor the case of China amongst the total deaths in ...    19    fbae70fc   \n",
       "c6b9d271  17845073a429f3      code  #Filetering the datasets\\npositive_condition = clinical_spectrum['sars_cov_2_exam_result'] == 'positive'\\npositive_c...     8    fbae70fc   \n",
       "1e2a3b00  17845073a429f3  markdown  <h3> Which are the most definitive clinical parameters that seperates poisitive and negative cases? </h3>\\n\\nGiving ...    11    fbae70fc   \n",
       "bc9d7947  17845073a429f3      code  #Making columns for the dataset\\npositive_mean = positive_mean.to_frame()\\npositive_mean = positive_mean.reset_index...    10    fbae70fc   \n",
       "c96f0973  17845073a429f3  markdown  Further research needs to be incorporated on does anyone of this figures leads to Cancer or these clincal informatio...    14    fbae70fc   \n",
       "33db9540  17845073a429f3  markdown  <h3> The next big steps </h3>\\n\\nWe analyzed and found out for roughly 17% of the deaths in COVID-19 Cancer plays a ...    23    fbae70fc   \n",
       "2d6201e0  17845073a429f3      code  #The most important clinical factors\\npositive_mean['Change'] =  positive_mean['Positive_figures'] - positive_mean['...    12    fbae70fc   \n",
       "\n",
       "         parent_id  pct_rank     label      pred  \n",
       "cell_id                                           \n",
       "502033a4       NaN  0.000000  0.000000 -0.003014  \n",
       "d50e67bb       NaN  0.750000  0.750000  0.057007  \n",
       "a42f4b7e       NaN  0.083333  0.083333  0.057831  \n",
       "205b4129       NaN  0.708333  0.708333  0.095581  \n",
       "7cc1fd2a       NaN  0.916667  0.916667  0.121704  \n",
       "68bcf209       NaN  0.833333  0.833333  0.134521  \n",
       "794feada       NaN  0.041667  0.041667  0.145874  \n",
       "b9d3bfc2       NaN  0.125000  0.125000  0.155273  \n",
       "a706930b       NaN  0.166667  0.166667  0.166667  \n",
       "1441e3fc       NaN  0.208333  0.208333  0.200073  \n",
       "a6f2a408       NaN  0.541667  0.541667  0.210571  \n",
       "d4e523f0       NaN  0.291667  0.291667  0.378662  \n",
       "f504d9dd       NaN  0.875000  0.875000  0.395996  \n",
       "ece1fb3b       NaN  0.250000  0.250000  0.250000  \n",
       "20e7ebe2       NaN  0.666667  0.666667  0.402832  \n",
       "cd8947db       NaN  0.625000  0.625000  0.492676  \n",
       "87794ae1       NaN  0.375000  0.375000  0.527832  \n",
       "a9d352d5       NaN  0.791667  0.791667  0.595703  \n",
       "c6b9d271       NaN  0.333333  0.333333  0.333333  \n",
       "1e2a3b00       NaN  0.458333  0.458333  0.778809  \n",
       "bc9d7947       NaN  0.416667  0.416667  0.416667  \n",
       "c96f0973       NaN  0.583333  0.583333  0.980469  \n",
       "33db9540       NaN  0.958333  0.958333  0.984863  \n",
       "2d6201e0       NaN  0.500000  0.500000  0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_score_sample = total_result.sort_values('kendall_score').iloc[:10,:]\n",
    "display(low_score_sample)\n",
    "\n",
    "# 실제 텍스트 확인\n",
    "def print_result(cell_tb, notebook_id, label_order, pred_order):\n",
    "    # cell tb 중 확인할 notebook_id sort\n",
    "    tmp_tb = cell_tb[cell_tb.id == notebook_id].copy()\n",
    "    tmp_tb = tmp_tb.set_index('cell_id')\n",
    "\n",
    "    print(f'>>> ---------- Notebook id: {notebook_id} ----------')\n",
    "\n",
    "#     # label 순서 대로 cell print\n",
    "#     print(f'>>> label_order result')\n",
    "#     display(tmp_tb.loc[label_order])\n",
    "#     for t in tmp_tb.loc[label_order].source.tolist():\n",
    "#         display(t)\n",
    "    \n",
    "    # pred order 대로 cell print\n",
    "    print(f'>>> pred_order_col result')\n",
    "    display(tmp_tb.loc[pred_order])\n",
    "#     for t in tmp_tb.loc[pred_order].source.tolist():\n",
    "#         display(t)\n",
    "    \n",
    "for row in low_score_sample.iterrows():\n",
    "    row = row[1]\n",
    "    print(row)\n",
    "    n_id = row.id\n",
    "    label_order = row.label_order\n",
    "    pred_order = row.pred_order\n",
    "    print_result(new_val_df, n_id, label_order, pred_order)\n",
    "    print('\\n\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bba75f",
   "metadata": {},
   "source": [
    "### kendall tau score가 낮은 id 실제 print되는 STT 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "beb74ba0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "################### Notebook id: 2fa3c4c997e1d1 ###################\n",
      "\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "Keras 전처리 층 API는 개발자들이 Keras 고유의 입력 처리 파이프라인을 만들 수 있게 해줍니다. 이 입력 처리 파이프라인들은 Keras가 아닌 작업 흐름 안에서 독립적인 사전 처리 코드로써 사용되고, 직접적으로 Keras 모델들과 결합되고, Keras SavedModel의 일부로써 수출될 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\nKeras 전처리 층 API는 개발자들이 Keras 고유의 입력 처리 파이프라인을 만들 수 있게 해줍니다. 이 입력 처리 파이프라인들은 Keras가 아닌 작업 흐름 안에서 독립적인 사전 처리 코드로써 사용되고, 직접적으로 Keras 모델들과 결합되고, Keras SavedModel의 일부로써 수출될 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 530, 254, 281, 46747]\n",
      "\n",
      "4. decode: \n",
      "<s>Keras 전처리 층 API는 개발자들이 Keras 고유의 입력 처리 파�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "[바닥에서 부터 이미지 분류](https://keras.io/examples/vision/image_classification_from_scratch/) 예제에서 비슷한 설정 활동을 볼 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n[바닥에서 부터 이미지 분류](https://keras.io/examples/vision/image_classification_from_scratch/) 예제에서 비슷한 설정 활동을 볼 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10975, 45209, 7487, 10674]\n",
      "\n",
      "4. decode: \n",
      "<s>[바닥에서 부터 이미지 분류](https://keras.io/examples/vision/image_classification_from_scratch/) 예제</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "[바닥에서 부터 텍스트 분류](https://keras.io/examples/nlp/text_classification_from_scratch/) 예제에서 `Embedding` 방식과 결합된 `TextVectorization` 층을 동작 속에서 볼 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n[바닥에서 부터 텍스트 분류](https://keras.io/examples/nlp/text_classification_from_scratch/) 예제에서 `Embedding` 방식과 결합된 `TextVectorization` 층을 동작 속에서 볼 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10975, 45209, 7487, 10674]\n",
      "\n",
      "4. decode: \n",
      "<s>[바닥에서 부터 텍스트 분류](https://keras.io/examples/nlp/text_classification_from_scratch/) 예�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "\n",
      "data = np.array([[0.1, 0.2, 0.3], [0.8, 0.9, 1.0], [1.5, 1.6, 1.7],])\n",
      "layer = preprocessing.Normalization()\n",
      "layer.adapt(data)\n",
      "normalized_data = layer(data)\n",
      "\n",
      "print(\"Features mean: %.2f\" % (normalized_data.numpy().mean()))\n",
      "print(\"Features std: %.2f\" % (normalized_data.numpy().std()))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\nimport numpy as np\\nimport tensorflow as tf\\nfrom tensorflow.keras.layers.experimental import preprocessing\\n\\ndata = np.array([[0.1, 0.2, 0.3], [0.8, 0.9, 1.0], [1.5, 1.6, 1.7],])\\nlayer = preprocessing.Normalization()\\nlayer.adapt(data)\\nnormalized_data = layer(data)\\n\\nprint(\"Features mean: %.2f\" % (normalized_data.numpy().mean()))\\nprint(\"Features std: %.2f\" % (normalized_data.numpy().std()))\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 41975, 295, 35187, 25]\n",
      "\n",
      "4. decode: \n",
      "<s>import numpy as np\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers.experimental import preprocessing\n",
      "\n",
      "data = np.array([[0.1, 0.2, 0.3], [0.8, 0.9, 1.0</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "## 추론 기간에 모델 안에서 전처리 수행의 장점\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n## 추론 기간에 모델 안에서 전처리 수행의 장점\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48342, 46747, 19002, 10674]\n",
      "\n",
      "4. decode: \n",
      "<s>## 추론 기간에 모델 안에서 전처리 수행의 장점</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "[바닥에서 부터 구조화된 데이터 분류](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/) 예제에서 `IntegerLookup`과 `CategoryEncoding` 층들을 작동하는 것으로 볼 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n[바닥에서 부터 구조화된 데이터 분류](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/) 예제에서 `IntegerLookup`과 `CategoryEncoding` 층들을 작동하는 것으로 볼 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10975, 45209, 7487, 10674]\n",
      "\n",
      "4. decode: \n",
      "<s>[바닥에서 부터 구조화된 데이터 분류](https://keras.io/examples/structured_data/struct</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "[바닥에서 부터 구조화된 데이터 분류](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/) 예제에서 `StringLookup`과 `CategoryEncoding` 층들을 작동하는 것으로 볼 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n[바닥에서 부터 구조화된 데이터 분류](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/) 예제에서 `StringLookup`과 `CategoryEncoding` 층들을 작동하는 것으로 볼 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10975, 45209, 7487, 10674]\n",
      "\n",
      "4. decode: \n",
      "<s>[바닥에서 부터 구조화된 데이터 분류](https://keras.io/examples/structured_data/struct</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "만약 초기에 전처리 층들을 [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) 파이프라인에 넣었다면, 전처리를 묶는 추론 모델을 내보낼 수 있습니다. 간단하게 전처리 층들과 학습 모델을 잇는 새로운 모델을 생성합니다:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n만약 초기에 전처리 층들을 [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) 파이프라인에 넣었다면, 전처리를 묶는 추론 모델을 내보낼 수 있습니다. 간단하게 전처리 층들과 학습 모델을 잇는 새로운 모델을 생성합니다:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 45209, 6248, 14285, 43998]\n",
      "\n",
      "4. decode: \n",
      "<s>만약 초기에 전처리 층들을 [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) �</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "data = [\n",
      "    \"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυθοι\",\n",
      "    \"γίγνοντ᾽, οὐδέ τι πάντα τελείεται ἀνθρώποισι.\",\n",
      "    \"δοιαὶ γάρ τε πύλαι ἀμενηνῶν εἰσὶν ὀνείρων:\",\n",
      "    \"αἱ μὲν γὰρ κεράεσσι τετεύχαται, αἱ δ᾽ ἐλέφαντι:\",\n",
      "    \"τῶν οἳ μέν κ᾽ ἔλθωσι διὰ πριστοῦ ἐλέφαντος,\",\n",
      "    \"οἵ ῥ᾽ ἐλεφαίρονται, ἔπε᾽ ἀκράαντα φέροντες:\",\n",
      "    \"οἱ δὲ διὰ ξεστῶν κεράων ἔλθωσι θύραζε,\",\n",
      "    \"οἵ ῥ᾽ ἔτυμα κραίνουσι, βροτῶν ὅτε κέν τις ἴδηται.\",\n",
      "]\n",
      "layer = preprocessing.TextVectorization()\n",
      "layer.adapt(data)\n",
      "vectorized_text = layer(data)\n",
      "print(vectorized_text)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\ndata = [\\n    \"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυθοι\",\\n    \"γίγνοντ᾽, οὐδέ τι πάντα τελείεται ἀνθρώποισι.\",\\n    \"δοιαὶ γάρ τε πύλαι ἀμενηνῶν εἰσὶν ὀνείρων:\",\\n    \"αἱ μὲν γὰρ κεράεσσι τετεύχαται, αἱ δ᾽ ἐλέφαντι:\",\\n    \"τῶν οἳ μέν κ᾽ ἔλθωσι διὰ πριστοῦ ἐλέφαντος,\",\\n    \"οἵ ῥ᾽ ἐλεφαίρονται, ἔπε᾽ ἀκράαντα φέροντες:\",\\n    \"οἱ δὲ διὰ ξεστῶν κεράων ἔλθωσι θύραζε,\",\\n    \"οἵ ῥ᾽ ἔτυμα κραίνουσι, βροτῶν ὅτε κέν τις ἴδηται.\",\\n]\\nlayer = preprocessing.TextVectorization()\\nlayer.adapt(data)\\nvectorized_text = layer(data)\\nprint(vectorized_text)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 23687, 5457, 646, 50118]\n",
      "\n",
      "4. decode: \n",
      "<s>data = [\n",
      "    \"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυ</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "# 전처리 층 다루기\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 전처리 층 다루기\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 46747, 21402, 11936]\n",
      "\n",
      "4. decode: \n",
      "<s># 전처리 층 다루기</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "## Keras 전처리 층\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n## Keras 전처리 층\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48342, 9508, 281, 46747]\n",
      "\n",
      "4. decode: \n",
      "<s>## Keras 전처리 층</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "결정적으로, 이 층들은 **학습 불가능**합니다. 이들의 상태는 학습 동안 설정되지 않습니다; **학습 이전에** 설정되어야 하며, 이 단계는 \"적응\"이라고 불립니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n결정적으로, 이 층들은 **학습 불가능**합니다. 이들의 상태는 학습 동안 설정되지 않습니다; **학습 이전에** 설정되어야 하며, 이 단계는 \"적응\"이라고 불립니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 46873, 14292, 7487, 43998]\n",
      "\n",
      "4. decode: \n",
      "<s>결정적으로, 이 층들은 **학습 불가능**합니다. 이들의 상�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "Keras 전처리 층으로, 완전히 종단하는 모델들(가공되지 않은 이미지나 가공되지 않은 구조화된 데이터를 입력으로 받으며, 자체적인 특징 표준화나 특징 값 색인을 다루는 모델들)을 만들고 수출할 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\nKeras 전처리 층으로, 완전히 종단하는 모델들(가공되지 않은 이미지나 가공되지 않은 구조화된 데이터를 입력으로 받으며, 자체적인 특징 표준화나 특징 값 색인을 다루는 모델들)을 만들고 수출할 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 530, 254, 281, 46747]\n",
      "\n",
      "4. decode: \n",
      "<s>Keras 전처리 층으로, 완전히 종단하는 모델들(가공되�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 텍스트를 토큰 색인들의 순열로 인코딩\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 텍스트를 토큰 색인들의 순열로 인코딩\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 1437, 47649, 5782]\n",
      "\n",
      "4. decode: \n",
      "<s>### 텍스트를 토큰 색인들의 순열로 인코딩</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "* `TextVectorization`: 문자열 토큰과 정수형 색인 사이의 대응을 가집니다.\n",
      "* `Normalization`: 특징의 평균과 표준 편차를 가집니다.\n",
      "* `StringLookup`과 `IntegerLookup`: 입력 값과 출력 색인 사이의 대응을 가집니다.\n",
      "* `CategoryEncoding`: 입력 값의 색인을 가집니다.\n",
      "* `Discretization`: 바구니 경계 값에 대한 정보를 가집니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n* `TextVectorization`: 문자열 토큰과 정수형 색인 사이의 대응을 가집니다.\\n* `Normalization`: 특징의 평균과 표준 편차를 가집니다.\\n* `StringLookup`과 `IntegerLookup`: 입력 값과 출력 색인 사이의 대응을 가집니다.\\n* `CategoryEncoding`: 입력 값의 색인을 가집니다.\\n* `Discretization`: 바구니 경계 값에 대한 정보를 가집니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 3226, 22209, 39645, 48417]\n",
      "\n",
      "4. decode: \n",
      "<s>* `TextVectorization`: 문자열 토큰과 정수형 색인 사이의 대응을 가집니</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### TF-IDF 가중치로 ngram의 밀집 행렬로써 텍스트 인코딩\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### TF-IDF 가중치로 ngram의 밀집 행렬로써 텍스트 인코딩\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 35690, 12, 2688]\n",
      "\n",
      "4. decode: \n",
      "<s>### TF-IDF 가중치로 ngram의 밀집 행렬로써 텍스트 인코딩</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
      "data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
      "layer = preprocessing.StringLookup(vocabulary=vocab)\n",
      "vectorized_data = layer(data)\n",
      "print(vectorized_data)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\nvocab = [\"a\", \"b\", \"c\", \"d\"]\\ndata = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\\nlayer = preprocessing.StringLookup(vocabulary=vocab)\\nvectorized_data = layer(data)\\nprint(vectorized_data)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 31375, 873, 5457, 46679]\n",
      "\n",
      "4. decode: \n",
      "<s>vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
      "data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
      "layer = preprocessing.StringLookup(vocabulary=vocab)\n",
      "vectorized_</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "* `CategoryEncoding` 층: 정수형 범주형 특징들을 one-hot, multi-hot, 또는 TF-IDF 밀집 표현으로 바꿉니다.\n",
      "* `Hashing` 층: \"해싱 기법\"으로도 알려진, 범주형 특징 해싱을 수행합니다.\n",
      "* `Discretization` 층: 연속형 수치형 특징들을 정수형 범주형 특징들로 바꿉니다.\n",
      "* `StringLookup` 층: 문자열 범주형 값들을 정수형 색인으로 바꿉니다.\n",
      "* `IntegerLookup` 층: 정수형 범주형 값들을 정수형 색인으로 바꿉니다.\n",
      "* `CategoryCrossing` 층: 범주형 특징들을 동시 발현 특징들로 결합합니다. 예를 들어, 만약 특징 값 \"a\"와 \"b\"를 가지고 있다면, 결합 특징 \"a와 b가 동시에 존재한다\"를 공급할 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n* `CategoryEncoding` 층: 정수형 범주형 특징들을 one-hot, multi-hot, 또는 TF-IDF 밀집 표현으로 바꿉니다.\\n* `Hashing` 층: \"해싱 기법\"으로도 알려진, 범주형 특징 해싱을 수행합니다.\\n* `Discretization` 층: 연속형 수치형 특징들을 정수형 범주형 특징들로 바꿉니다.\\n* `StringLookup` 층: 문자열 범주형 값들을 정수형 색인으로 바꿉니다.\\n* `IntegerLookup` 층: 정수형 범주형 값들을 정수형 색인으로 바꿉니다.\\n* `CategoryCrossing` 층: 범주형 특징들을 동시 발현 특징들로 결합합니다. 예를 들어, 만약 특징 값 \"a\"와 \"b\"를 가지고 있다면, 결합 특징 \"a와 b가 동시에 존재한다\"를 공급할 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 3226, 22209, 46308, 45780]\n",
      "\n",
      "4. decode: \n",
      "<s>* `CategoryEncoding` 층: 정수형 범주형 특징들을 one-hot, multi-hot, 또는 TF-IDF 밀�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이것은 `TextVectorization`과 모든 구조화된 데이터 전처리 층들에 대해 최선의 선택입니다. 이것은 CPU 위에서 학습을 시키고 이미지 전처리 층들을 사용하는 경우에도 좋은 선택지입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이것은 `TextVectorization`과 모든 구조화된 데이터 전처리 층들에 대해 최선의 선택입니다. 이것은 CPU 위에서 학습을 시키고 이미지 전처리 층들을 사용하는 경우에도 좋은 선택지입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 46873, 14292]\n",
      "\n",
      "4. decode: \n",
      "<s>이것은 `TextVectorization`과 모든 구조화된 데이터 전처리 층들에 �</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "## 사용 가능한 전처리 층\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n## 사용 가능한 전처리 층\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48342, 46747, 49171, 43998]\n",
      "\n",
      "4. decode: \n",
      "<s>## 사용 가능한 전처리 층</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "```python\n",
      "dataset = dataset.map(\n",
      "    lambda x, y: (preprocessing_layer(x), y))\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n```python\\ndataset = dataset.map(\\n    lambda x, y: (preprocessing_layer(x), y))\\n```\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 49519, 12905, 49119, 50118]\n",
      "\n",
      "4. decode: \n",
      "<s>```python\n",
      "dataset = dataset.map(\n",
      "    lambda x, y: (preprocessing_layer(x), y))\n",
      "```</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### multi-hot 인코딩으로 ngram의 밀집 행렬로써 텍스트 인코딩\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### multi-hot 인코딩으로 ngram의 밀집 행렬로써 텍스트 인코딩\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 3228, 12, 10120]\n",
      "\n",
      "4. decode: \n",
      "<s>### multi-hot 인코딩으로 ngram의 밀집 행렬로써 텍스트 인코딩</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### one-hot 인코딩을 통한 정수형 범주형 특징 인코딩\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### one-hot 인코딩을 통한 정수형 범주형 특징 인코딩\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 65, 12, 10120]\n",
      "\n",
      "4. decode: \n",
      "<s>### one-hot 인코딩을 통한 정수형 범주형 특징 인코딩</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 정수형 범주형 특징에 해싱 기법 적용\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 정수형 범주형 특징에 해싱 기법 적용\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 46747, 21402, 15722]\n",
      "\n",
      "4. decode: \n",
      "<s>### 정수형 범주형 특징에 해싱 기법 적용</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### one-hot 인코딩을 통한 문자열 범주형 특징 인코딩\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### one-hot 인코딩을 통한 문자열 범주형 특징 인코딩\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 65, 12, 10120]\n",
      "\n",
      "4. decode: \n",
      "<s>### one-hot 인코딩을 통한 문자열 범주형 특징 인코딩</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "from tensorflow import keras\n",
      "from tensorflow.keras import layers\n",
      "\n",
      "# 수평 뒤집기, 회전, 확대로 데이터 증강 단계를 생성합니다\n",
      "data_augmentation = keras.Sequential(\n",
      "    [\n",
      "        preprocessing.RandomFlip(\"horizontal\"),\n",
      "        preprocessing.RandomRotation(0.1),\n",
      "        preprocessing.RandomZoom(0.1),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# 증강 단계를 포함하는 모델을 생성합니다\n",
      "input_shape = (32, 32, 3)\n",
      "classes = 10\n",
      "inputs = keras.Input(shape=input_shape)\n",
      "# 이미지를 증강합니다\n",
      "x = data_augmentation(inputs)\n",
      "# 이미지 값들을 [0, 1]로 재조정합니다\n",
      "x = preprocessing.Rescaling(1.0 / 255)(x)\n",
      "# 모델의 나머지를 추가합니다\n",
      "outputs = keras.applications.ResNet50(\n",
      "    weights=None, input_shape=input_shape, classes=classes\n",
      ")(x)\n",
      "model = keras.Model(inputs, outputs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\n\\n# 수평 뒤집기, 회전, 확대로 데이터 증강 단계를 생성합니다\\ndata_augmentation = keras.Sequential(\\n    [\\n        preprocessing.RandomFlip(\"horizontal\"),\\n        preprocessing.RandomRotation(0.1),\\n        preprocessing.RandomZoom(0.1),\\n    ]\\n)\\n\\n# 증강 단계를 포함하는 모델을 생성합니다\\ninput_shape = (32, 32, 3)\\nclasses = 10\\ninputs = keras.Input(shape=input_shape)\\n# 이미지를 증강합니다\\nx = data_augmentation(inputs)\\n# 이미지 값들을 [0, 1]로 재조정합니다\\nx = preprocessing.Rescaling(1.0 / 255)(x)\\n# 모델의 나머지를 추가합니다\\noutputs = keras.applications.ResNet50(\\n    weights=None, input_shape=input_shape, classes=classes\\n)(x)\\nmodel = keras.Model(inputs, outputs)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 7761, 7281, 368, 19322]\n",
      "\n",
      "4. decode: \n",
      "<s>from tensorflow import keras\n",
      "from tensorflow.keras import layers\n",
      "\n",
      "# 수평 뒤집기, 회전, 확대로 데이터</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 구조화된 데이터 전처리 층\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 구조화된 데이터 전처리 층\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 1437, 46873, 8906]\n",
      "\n",
      "4. decode: \n",
      "<s>### 구조화된 데이터 전처리 층</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "만약 각 값이 데이터에서 오직 몇번만 나타나는 많은 다른 값들(대략 10e3 이상)을 가질 수 있는 범주형 특징을 가지고 있다면, 특징값들을 색인하고 one-hot 인코딩을 하는 것은 비실용적이고 비효율적이게 됩니다. 대신, \"해싱 기법\"을 적용하는 것이 좋은 발상이 될 수 있습니다: 값을 고정된 크기의 벡터로 해싱합니다. 이것은 특징 공간의 크기를 관리할 수 있게 유지하고 명백한 색인에 대한 필요성을 제거합니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n만약 각 값이 데이터에서 오직 몇번만 나타나는 많은 다른 값들(대략 10e3 이상)을 가질 수 있는 범주형 특징을 가지고 있다면, 특징값들을 색인하고 one-hot 인코딩을 하는 것은 비실용적이고 비효율적이게 됩니다. 대신, \"해싱 기법\"을 적용하는 것이 좋은 발상이 될 수 있습니다: 값을 고정된 크기의 벡터로 해싱합니다. 이것은 특징 공간의 크기를 관리할 수 있게 유지하고 명백한 색인에 대한 필요성을 제거합니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 45209, 6248, 14285, 43998]\n",
      "\n",
      "4. decode: \n",
      "<s>만약 각 값이 데이터에서 오직 몇번만 나타나는 많은</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "여기 사전 계산된 사전으로 `StringLookup` 층을 생성하는 예제입니다:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n여기 사전 계산된 사전으로 `StringLookup` 층을 생성하는 예제입니다:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 43998, 6800, 11582, 46873]\n",
      "\n",
      "4. decode: \n",
      "<s>여기 사전 계산된 사전으로 `StringLookup` 층을 생성하는 예제입</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "## 빠른 사용법\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n## 빠른 사용법\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48342, 47672, 9253, 21402]\n",
      "\n",
      "4. decode: \n",
      "<s>## 빠른 사용법</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "* `TextVectorization` 층: 가공되지 않은 문자열을 `Embedding` 층이나 `Dense` 층에 의해 읽힐 수 있는 인코딩된 표현으로 바꿉니다.\n",
      "* `Normalization` 층: 입력 특징들의 특징별 표준화를 수행합니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n* `TextVectorization` 층: 가공되지 않은 문자열을 `Embedding` 층이나 `Dense` 층에 의해 읽힐 수 있는 인코딩된 표현으로 바꿉니다.\\n* `Normalization` 층: 입력 특징들의 특징별 표준화를 수행합니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 3226, 22209, 39645, 48417]\n",
      "\n",
      "4. decode: \n",
      "<s>* `TextVectorization` 층: 가공되지 않은 문자열을 `Embedding` 층이나 `Dense` 층에</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "**선택지 2**: 전처리된 데이터의 묶음을 내놓을 수 있는 데이터 세트를 얻기 위하여, 다음과 같이, [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)에 적용합니다:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n**선택지 2**: 전처리된 데이터의 묶음을 내놓을 수 있는 데이터 세트를 얻기 위하여, 다음과 같이, [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)에 적용합니다:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 12606, 43998, 11936, 21402]\n",
      "\n",
      "4. decode: \n",
      "<s>**선택지 2**: 전처리된 데이터의 묶음을 내놓을 수 있는 데</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이 층들은 구조화된 데이터 인코딩과 특징 공학을 위한 것입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이 층들은 구조화된 데이터 인코딩과 특징 공학을 위한 것입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 46747, 18537]\n",
      "\n",
      "4. decode: \n",
      "<s>이 층들은 구조화된 데이터 인코딩과 특징 공학을 위�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이것은 `Dense` 층에 전달되는 텍스트를 전처리해야 하는 방법입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이것은 `Dense` 층에 전달되는 텍스트를 전처리해야 하는 방법입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 46873, 14292]\n",
      "\n",
      "4. decode: \n",
      "<s>이것은 `Dense` 층에 전달되는 텍스트를 전처리해야 하는 �</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이것은 `Dense` 층에 텍스트를 넘기기 전에 전처리하는 또다른 방법입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이것은 `Dense` 층에 텍스트를 넘기기 전에 전처리하는 또다른 방법입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 46873, 14292]\n",
      "\n",
      "4. decode: \n",
      "<s>이것은 `Dense` 층에 텍스트를 넘기기 전에 전처리하는 또</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "선택지 2를 사용해 진행한다고 해도, 추후에 전처리 층들을 포함할 추론만 수행하는 종단 간 모델을 내보내고 싶을 수도 있습니다. 이것을 수행하는 핵심 장점은 **모델을 휴대 가능하게 만든다**는 것과 **[학습/제공 왜곡](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew)을 줄이게 도와준다**는 것입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n선택지 2를 사용해 진행한다고 해도, 추후에 전처리 층들을 포함할 추론만 수행하는 종단 간 모델을 내보내고 싶을 수도 있습니다. 이것을 수행하는 핵심 장점은 **모델을 휴대 가능하게 만든다**는 것과 **[학습/제공 왜곡](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew)을 줄이게 도와준다**는 것입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 43998, 11936, 21402, 47649]\n",
      "\n",
      "4. decode: \n",
      "<s>선택지 2를 사용해 진행한다고 해도, 추후에 전처리 층�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "## 모델 이전 혹은 안에서 데이터 전처리\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n## 모델 이전 혹은 안에서 데이터 전처리\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48342, 47672, 10278, 11423]\n",
      "\n",
      "4. decode: \n",
      "<s>## 모델 이전 혹은 안에서 데이터 전처리</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "# 몇개의 데이터를 불러옵니다\n",
      "(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n",
      "x_train = x_train.reshape((len(x_train), -1))\n",
      "input_shape = x_train.shape[1:]\n",
      "classes = 10\n",
      "\n",
      "# 학습 데이터를 사용해 정규화 층과 그 내부 상태를 생성합니다\n",
      "normalizer = preprocessing.Normalization()\n",
      "normalizer.adapt(x_train)\n",
      "\n",
      "# 정규화 층을 포함하는 모델을 생성합니다\n",
      "inputs = keras.Input(shape=input_shape)\n",
      "x = normalizer(inputs)\n",
      "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
      "model = keras.Model(inputs, outputs)\n",
      "\n",
      "# 모델을 학습시킵니다\n",
      "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
      "model.fit(x_train, y_train)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 몇개의 데이터를 불러옵니다\\n(x_train, y_train), _ = keras.datasets.cifar10.load_data()\\nx_train = x_train.reshape((len(x_train), -1))\\ninput_shape = x_train.shape[1:]\\nclasses = 10\\n\\n# 학습 데이터를 사용해 정규화 층과 그 내부 상태를 생성합니다\\nnormalizer = preprocessing.Normalization()\\nnormalizer.adapt(x_train)\\n\\n# 정규화 층을 포함하는 모델을 생성합니다\\ninputs = keras.Input(shape=input_shape)\\nx = normalizer(inputs)\\noutputs = layers.Dense(classes, activation=\"softmax\")(x)\\nmodel = keras.Model(inputs, outputs)\\n\\n# 모델을 학습시킵니다\\nmodel.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\\nmodel.fit(x_train, y_train)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 47672, 10278, 6382]\n",
      "\n",
      "4. decode: \n",
      "<s># 몇개의 데이터를 불러옵니다\n",
      "(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n",
      "</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 수치형 특징 정규화\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 수치형 특징 정규화\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 46747, 23133, 711]\n",
      "\n",
      "4. decode: \n",
      "<s>### 수치형 특징 정규화</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "* `Resizing` 층: 이미지 묶음을 목표 크기로 조절합니다.\n",
      "* `Rescaling` 층: 이미지 묶음의 값을 재조정하고 옮깁니다(예를 들어, `[0, 255]` 범위의 입력에서 `[0, 1]` 범위의 입력으로 갑니다).\n",
      "* `CentorCrop` 층: 이미지 묶음의 중심 조각을 반환합니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n* `Resizing` 층: 이미지 묶음을 목표 크기로 조절합니다.\\n* `Rescaling` 층: 이미지 묶음의 값을 재조정하고 옮깁니다(예를 들어, `[0, 255]` 범위의 입력에서 `[0, 1]` 범위의 입력으로 갑니다).\\n* `CentorCrop` 층: 이미지 묶음의 중심 조각을 반환합니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 3226, 22209, 20028, 2787]\n",
      "\n",
      "4. decode: \n",
      "<s>* `Resizing` 층: 이미지 묶음을 목표 크기로 조절합니다.\n",
      "* `Rescaling` �</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "전처리 층들을 사용할 수 있는 두가지 방법이 있습니다:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n전처리 층들을 사용할 수 있는 두가지 방법이 있습니다:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 43998, 21402, 11936, 43998]\n",
      "\n",
      "4. decode: \n",
      "<s>전처리 층들을 사용할 수 있는 두가지 방법이 있습니다:</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이것은 `Embedding` 층에 넘겨지는 텍스트를 어떻게 전처리해야 하는지 입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이것은 `Embedding` 층에 넘겨지는 텍스트를 어떻게 전처리해야 하는지 입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 46873, 14292]\n",
      "\n",
      "4. decode: \n",
      "<s>이것은 `Embedding` 층에 넘겨지는 텍스트를 어떻게 전처리�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "모든 데이터 전처리가 모델의 일부라면, 다른 사람들은 각 특징들이 어떻게 인코딩 & 표준화되기를 기대하는지에 대해 알고 있지 않아도 모델을 불러오고 사용할 수 있을 것입니다. 추론 모델은 원본 이미지나 원본 구조화된 데이터를 처리할 수 있을 것이고, 모델의 사용자들이 텍스트에 대해 사용된 토큰화 계획, 범주형 특징들에 대해 사용된 색인 계획, 이미지 픽셀값들이 `[-1, +1]`이나 `[0, 1]`로 표준화되었는지 여부 등 자세한 내용을 알도록 요구하지 않을 것입니다. 이것은 TensorFlow.js와 같은 다른 런타임에 모델을 내보낼 때 특별하게 강력합니다: JavaScript에서 전처리 파이프라인을 재구형하지 않아도 됩니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n모든 데이터 전처리가 모델의 일부라면, 다른 사람들은 각 특징들이 어떻게 인코딩 & 표준화되기를 기대하는지에 대해 알고 있지 않아도 모델을 불러오고 사용할 수 있을 것입니다. 추론 모델은 원본 이미지나 원본 구조화된 데이터를 처리할 수 있을 것이고, 모델의 사용자들이 텍스트에 대해 사용된 토큰화 계획, 범주형 특징들에 대해 사용된 색인 계획, 이미지 픽셀값들이 `[-1, +1]`이나 `[0, 1]`로 표준화되었는지 여부 등 자세한 내용을 알도록 요구하지 않을 것입니다. 이것은 TensorFlow.js와 같은 다른 런타임에 모델을 내보낼 때 특별하게 강력합니다: JavaScript에서 전처리 파이프라인을 재구형하지 않아도 됩니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 45209, 10278, 11423, 45209]\n",
      "\n",
      "4. decode: \n",
      "<s>모든 데이터 전처리가 모델의 일부라면, 다른 사람들�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "**선택지 1**: 다음과 같이, 모델의 일부로 만듭니다:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n**선택지 1**: 다음과 같이, 모델의 일부로 만듭니다:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 12606, 43998, 11936, 21402]\n",
      "\n",
      "4. decode: \n",
      "<s>**선택지 1**: 다음과 같이, 모델의 일부로 만듭니다:</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "몇개의 전처리 층들은 학습 데이터의 표본을 기반으로 계산되야 하는 내부 상태를 가집니다. 상태를 가지는 전처리 층들의 목록은:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n몇개의 전처리 층들은 학습 데이터의 표본을 기반으로 계산되야 하는 내부 상태를 가집니다. 상태를 가지는 전처리 층들의 목록은:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 45209, 10278, 6382, 46873]\n",
      "\n",
      "4. decode: \n",
      "<s>몇개의 전처리 층들은 학습 데이터의 표본을 기반으�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 이미지 데이터 증강 층\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 이미지 데이터 증강 층\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 46747, 46, 20024]\n",
      "\n",
      "4. decode: \n",
      "<s>### 이미지 데이터 증강 층</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 이미지 데이터 증강 (기기 위에서)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 이미지 데이터 증강 (기기 위에서)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 46747, 46, 20024]\n",
      "\n",
      "4. decode: \n",
      "<s>### 이미지 데이터 증강 (기기 위에서)</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "```python\n",
      "inputs = keras.Input(shape=input_shape)\n",
      "x = preprocessing_layer(inputs)\n",
      "outputs = rest_of_the_model(x)\n",
      "model = keras.Model(inputs, outputs)\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n```python\\ninputs = keras.Input(shape=input_shape)\\nx = preprocessing_layer(inputs)\\noutputs = rest_of_the_model(x)\\nmodel = keras.Model(inputs, outputs)\\n```\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 49519, 12905, 49119, 50118]\n",
      "\n",
      "4. decode: \n",
      "<s>```python\n",
      "inputs = keras.Input(shape=input_shape)\n",
      "x = preprocessing_layer(inputs)\n",
      "outputs = rest_of_the_model(x)\n",
      "model = keras.Model(inputs, outputs)\n",
      "```</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "# 몇가지 연습용 데이터를 정의합니다\n",
      "data = tf.constant([\"a\", \"b\", \"c\", \"b\", \"c\", \"a\"])\n",
      "\n",
      "# 특징값들의 색인을 만들기 위해 StringLookup을 사용합니다\n",
      "indexer = preprocessing.StringLookup()\n",
      "indexer.adapt(data)\n",
      "\n",
      "# 정수형 색인들을 one-hot 벡터로 인코딩하기 위해 CategoryEncoding을 사용합니다\n",
      "encoder = preprocessing.CategoryEncoding(output_mode=\"binary\")\n",
      "encoder.adapt(indexer(data))\n",
      "\n",
      "# (알 수 없는 특징값을 포함하는) 새로운 평가 데이터를 변환합니다\n",
      "test_data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"e\", \"\"])\n",
      "encoded_data = encoder(indexer(test_data))\n",
      "print(encoded_data)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 몇가지 연습용 데이터를 정의합니다\\ndata = tf.constant([\"a\", \"b\", \"c\", \"b\", \"c\", \"a\"])\\n\\n# 특징값들의 색인을 만들기 위해 StringLookup을 사용합니다\\nindexer = preprocessing.StringLookup()\\nindexer.adapt(data)\\n\\n# 정수형 색인들을 one-hot 벡터로 인코딩하기 위해 CategoryEncoding을 사용합니다\\nencoder = preprocessing.CategoryEncoding(output_mode=\"binary\")\\nencoder.adapt(indexer(data))\\n\\n# (알 수 없는 특징값을 포함하는) 새로운 평가 데이터를 변환합니다\\ntest_data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"e\", \"\"])\\nencoded_data = encoder(indexer(test_data))\\nprint(encoded_data)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 47672, 10278, 6382]\n",
      "\n",
      "4. decode: \n",
      "<s># 몇가지 연습용 데이터를 정의합니다\n",
      "data = tf.constant([\"a\", \"b\", \"c\", \"b\", \"</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "추가적으로, 적응 가능한 층들은 생성자 인자나 가중치 대입을 통해 상태를 직접적으로 설정할 수 있는 선택지를 항상 제공합니다. 만약 대상 상태값이 층 생성 기간에 알려져 있거나, `adapt()` 호출의 밖에서 계산된다면, 그들은 층의 내부 계산에 기대지 않고 설정될 수 있습니다. 예를 들어, `TextVectorization`, `StringLookup`, 또는 `IntegerLookup` 층들에 대한 외부 사전 파일들이 이미 존재한다면, 그것들은 층의 생성자 인자에 사전 파일에 대한 경로를 넘겨줌으로써 검색표에 직접적으로 불러와질 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n추가적으로, 적응 가능한 층들은 생성자 인자나 가중치 대입을 통해 상태를 직접적으로 설정할 수 있는 선택지를 항상 제공합니다. 만약 대상 상태값이 층 생성 기간에 알려져 있거나, `adapt()` 호출의 밖에서 계산된다면, 그들은 층의 내부 계산에 기대지 않고 설정될 수 있습니다. 예를 들어, `TextVectorization`, `StringLookup`, 또는 `IntegerLookup` 층들에 대한 외부 사전 파일들이 이미 존재한다면, 그것들은 층의 생성자 인자에 사전 파일에 대한 경로를 넘겨줌으로써 검색표에 직접적으로 불러와질 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 43998, 19002, 10674, 46873]\n",
      "\n",
      "4. decode: \n",
      "<s>추가적으로, 적응 가능한 층들은 생성자 인자나 가�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 이미지 전처리 층\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 이미지 전처리 층\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 46747, 46, 20024]\n",
      "\n",
      "4. decode: \n",
      "<s>### 이미지 전처리 층</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이 층들은 이미지 묶음에 무작위 증강 변환을 적용합니다. 오직 학습 동안에만 활성화됩니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이 층들은 이미지 묶음에 무작위 증강 변환을 적용합니다. 오직 학습 동안에만 활성화됩니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 46747, 18537]\n",
      "\n",
      "4. decode: \n",
      "<s>이 층들은 이미지 묶음에 무작위 증강 변환을 적용합니다</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "```python\n",
      "inputs = keras.Input(shape=input_shape)\n",
      "x = preprocessing_layer(inputs)\n",
      "outputs = training_model(x)\n",
      "inference_model = keras.Model(inputs, outputs)\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n```python\\ninputs = keras.Input(shape=input_shape)\\nx = preprocessing_layer(inputs)\\noutputs = training_model(x)\\ninference_model = keras.Model(inputs, outputs)\\n```\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 49519, 12905, 49119, 50118]\n",
      "\n",
      "4. decode: \n",
      "<s>```python\n",
      "inputs = keras.Input(shape=input_shape)\n",
      "x = preprocessing_layer(inputs)\n",
      "outputs = training_model(x)\n",
      "inference_model = keras.Model(inputs, outputs)\n",
      "```</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "# 몇가지 연습용 데이터를 정의합니다\n",
      "data = tf.constant([10, 20, 20, 10, 30, 0])\n",
      "\n",
      "# 특징값들의 색인을 만들기 위해 IntegerLookup을 사용합니다\n",
      "indexer = preprocessing.IntegerLookup()\n",
      "indexer.adapt(data)\n",
      "\n",
      "# 정수형 색인들을 one-hot 벡터로 인코딩하기 위해 CategoryEncoding을 사용합니다\n",
      "encoder = preprocessing.CategoryEncoding(output_mode=\"binary\")\n",
      "encoder.adapt(indexer(data))\n",
      "\n",
      "# (알 수 없는 특징값을 포함하는) 새로운 평가 데이터를 변환합니다\n",
      "test_data = tf.constant([10, 10, 20, 50, 60, 0])\n",
      "encoded_data = encoder(indexer(test_data))\n",
      "print(encoded_data)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 몇가지 연습용 데이터를 정의합니다\\ndata = tf.constant([10, 20, 20, 10, 30, 0])\\n\\n# 특징값들의 색인을 만들기 위해 IntegerLookup을 사용합니다\\nindexer = preprocessing.IntegerLookup()\\nindexer.adapt(data)\\n\\n# 정수형 색인들을 one-hot 벡터로 인코딩하기 위해 CategoryEncoding을 사용합니다\\nencoder = preprocessing.CategoryEncoding(output_mode=\"binary\")\\nencoder.adapt(indexer(data))\\n\\n# (알 수 없는 특징값을 포함하는) 새로운 평가 데이터를 변환합니다\\ntest_data = tf.constant([10, 10, 20, 50, 60, 0])\\nencoded_data = encoder(indexer(test_data))\\nprint(encoded_data)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 47672, 10278, 6382]\n",
      "\n",
      "4. decode: \n",
      "<s># 몇가지 연습용 데이터를 정의합니다\n",
      "data = tf.constant([10, 20, 20, 10, 30, 0])\n",
      "</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이미지 증강 층들은 학습 동안에만 (`Dropout` 층과 유사하게) 활성화된다는 것을 주목하세요.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이미지 증강 층들은 학습 동안에만 (`Dropout` 층과 유사하게) 활성화된다는 것을 주목하세요.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 45209, 10965]\n",
      "\n",
      "4. decode: \n",
      "<s>이미지 증강 층들은 학습 동안에만 (`Dropout` 층과 유사하게)</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이 방법으로는, 전처리가 기기 위에서, 나머지 모델 실행과 동기화되어 일어날 것이며, 이는 GPU 가속에 이익이 될 것이라는 뜻입니다. GPU 위에서 학습시키고 있다면, 이것은 `Normalization` 층에 대해, 그리고 모든 이미지 전처리와 데이터 증강 층들에 대해 최선의 선택입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이 방법으로는, 전처리가 기기 위에서, 나머지 모델 실행과 동기화되어 일어날 것이며, 이는 GPU 가속에 이익이 될 것이라는 뜻입니다. GPU 위에서 학습시키고 있다면, 이것은 `Normalization` 층에 대해, 그리고 모든 이미지 전처리와 데이터 증강 층들에 대해 최선의 선택입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 47672, 7487]\n",
      "\n",
      "4. decode: \n",
      "<s>이 방법으로는, 전처리가 기기 위에서, 나머지 모델</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이 층들은 이미지 모델의 입력들을 표준화하기 위한 것입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이 층들은 이미지 모델의 입력들을 표준화하기 위한 것입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 46747, 18537]\n",
      "\n",
      "4. decode: \n",
      "<s>이 층들은 이미지 모델의 입력들을 표준화하기 위한 것</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이 방법으로는, 전처리가 CPU 위에서, 비동기적으로 일어날 것이며, 모델에 들어가기 전에 임시 저장될 것입니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이 방법으로는, 전처리가 CPU 위에서, 비동기적으로 일어날 것이며, 모델에 들어가기 전에 임시 저장될 것입니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 47672, 7487]\n",
      "\n",
      "4. decode: \n",
      "<s>이 방법으로는, 전처리가 CPU 위에서, 비동기적으로 일</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "## `adapt()` 메소드\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n## `adapt()` 메소드\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48342, 22209, 43199, 43048]\n",
      "\n",
      "4. decode: \n",
      "<s>## `adapt()` 메소드</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "### 핵심 전처리 층\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n### 핵심 전처리 층\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48134, 1437, 48589, 8906]\n",
      "\n",
      "4. decode: \n",
      "<s>### 핵심 전처리 층</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "0번째 색인은 (빈 문자열 `\"\"`로써 특정해야 하는)결측값들을 위해 보존되며, 1번째 색인은 사전 외 값들(`adapt()` 동안 보이지 않은 값들)을 위해 보존됩니다. 이것은 `IntegerLookup`의 `mask_value`와 `oov_value` 생성자 인자들을 사용함으로써 설정할 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n0번째 색인은 (빈 문자열 `\"\"`로써 특정해야 하는)결측값들을 위해 보존되며, 1번째 색인은 사전 외 값들(`adapt()` 동안 보이지 않은 값들)을 위해 보존됩니다. 이것은 `IntegerLookup`의 `mask_value`와 `oov_value` 생성자 인자들을 사용함으로써 설정할 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 288, 45209, 14292, 23133]\n",
      "\n",
      "4. decode: \n",
      "<s>0번째 색인은 (빈 문자열 `\"\"`로써 특정해야 하는)결측�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "0번째 색인은 (빈 문자열 `\"\"`로써 특정해야 하는)결측값들을 위해 보존되며, 1번째 색인은 사전 외 값들(`adapt()` 동안 보이지 않은 값들)을 위해 보존됩니다. 이것은 `StringLookup`의 `mask_token`과 `oov_token` 생성자 인자들을 사용함으로써 설정할 수 있습니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n0번째 색인은 (빈 문자열 `\"\"`로써 특정해야 하는)결측값들을 위해 보존되며, 1번째 색인은 사전 외 값들(`adapt()` 동안 보이지 않은 값들)을 위해 보존됩니다. 이것은 `StringLookup`의 `mask_token`과 `oov_token` 생성자 인자들을 사용함으로써 설정할 수 있습니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 288, 45209, 14292, 23133]\n",
      "\n",
      "4. decode: \n",
      "<s>0번째 색인은 (빈 문자열 `\"\"`로써 특정해야 하는)결측�</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "이런 모델을 학습시킬 때에는, 최고의 성능을 위해, (위의 텍스트 분류 예제에서 했던 것인) 입력 파이프라인의 부분으로 `TextVectorization` 층을 사용해야 합니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n이런 모델을 학습시킬 때에는, 최고의 성능을 위해, (위의 텍스트 분류 예제에서 했던 것인) 입력 파이프라인의 부분으로 `TextVectorization` 층을 사용해야 합니다.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 48280, 20024, 45209, 4333]\n",
      "\n",
      "4. decode: \n",
      "<s>이런 모델을 학습시킬 때에는, 최고의 성능을 위해, (위의</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "# 표본 데이터: 0과 100,000 사이의 10,000개의 무작위 정수\n",
      "data = np.random.randint(0, 100000, size=(10000, 1))\n",
      "\n",
      "# [0, 64] 범위로 값들을 해싱하기 위해 Hashing 층을 사용합니다\n",
      "hasher = preprocessing.Hashing(num_bins=64, salt=1337)\n",
      "\n",
      "# 해싱된 값들을 one-hot 인코딩하기 위해 CategoryEncoding 층을 사용합니다\n",
      "encoder = preprocessing.CategoryEncoding(max_tokens=64, output_mode=\"binary\")\n",
      "encoded_data = encoder(hasher(data))\n",
      "print(encoded_data.shape)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 표본 데이터: 0과 100,000 사이의 10,000개의 무작위 정수\\ndata = np.random.randint(0, 100000, size=(10000, 1))\\n\\n# [0, 64] 범위로 값들을 해싱하기 위해 Hashing 층을 사용합니다\\nhasher = preprocessing.Hashing(num_bins=64, salt=1337)\\n\\n# 해싱된 값들을 one-hot 인코딩하기 위해 CategoryEncoding 층을 사용합니다\\nencoder = preprocessing.CategoryEncoding(max_tokens=64, output_mode=\"binary\")\\nencoded_data = encoder(hasher(data))\\nprint(encoded_data.shape)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 1437, 47649, 3602]\n",
      "\n",
      "4. decode: \n",
      "<s># 표본 데이터: 0과 100,000 사이의 10,000개의 무작위 정수\n",
      "data = np.random.randint</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "`adapt()` 메소드는 Numpy 배열이나 [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) 객체 모두 받습니다. `StringLookup`과 `TextVectorization`의 경우에, 문자열들의 목록을 넘겨줄 수 있습니다:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n`adapt()` 메소드는 Numpy 배열이나 [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) 객체 모두 받습니다. `StringLookup`과 `TextVectorization`의 경우에, 문자열들의 목록을 넘겨줄 수 있습니다:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 12905, 43199, 43048, 12905]\n",
      "\n",
      "4. decode: \n",
      "<s>`adapt()` 메소드는 Numpy 배열이나 [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Datas</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "`adapt()` 메소드를 통해 학습 데이터에 전처리 층을 노출시킴으로써 상태를 설정할 수 있습니다:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n`adapt()` 메소드를 통해 학습 데이터에 전처리 층을 노출시킴으로써 상태를 설정할 수 있습니다:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 12905, 43199, 43048, 12905]\n",
      "\n",
      "4. decode: \n",
      "<s>`adapt()` 메소드를 통해 학습 데이터에 전처리 층을 노출시</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: markdown\n",
      "\n",
      "2. og_source: \n",
      "* `RandomCrop` 층\n",
      "* `RandomFlip` 층\n",
      "* `RandomTranslation` 층\n",
      "* `RandomRotation` 층\n",
      "* `RandomZoom` 층\n",
      "* `RandomHeight` 층\n",
      "* `RandomWidth` 층\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n* `RandomCrop` 층\\n* `RandomFlip` 층\\n* `RandomTranslation` 층\\n* `RandomRotation` 층\\n* `RandomZoom` 층\\n* `RandomHeight` 층\\n* `RandomWidth` 층\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 3226, 22209, 45134, 347]\n",
      "\n",
      "4. decode: \n",
      "<s>* `RandomCrop` 층\n",
      "* `RandomFlip` 층\n",
      "* `RandomTranslation` 층\n",
      "* `RandomRotation` 층\n",
      "* `RandomZoom` 층\n",
      "* `RandomHeight` 층\n",
      "* `RandomWidth</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "# 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\n",
      "data = tf.constant(\n",
      "    [\n",
      "        \"The Brain is wider than the Sky\",\n",
      "        \"For put them side by side\",\n",
      "        \"The one the other will contain\",\n",
      "        \"With ease and You beside\",\n",
      "    ]\n",
      ")\n",
      "# \"정수\" 출력 방식으로 TextVectorization을 생성합니다\n",
      "text_vectorizer = preprocessing.TextVectorization(output_mode=\"int\")\n",
      "# `adapt()`를 통해 사전을 색인합니다\n",
      "text_vectorizer.adapt(data)\n",
      "\n",
      "# get_vocabulary()를 통해 색인한 사전을 받아올 수 있습니다\n",
      "vocab = text_vectorizer.get_vocabulary()\n",
      "print(\"Vocabulary:\", vocab)\n",
      "\n",
      "# Embedding + LSTM 모델을 생성합니다\n",
      "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
      "x = text_vectorizer(inputs)\n",
      "x = layers.Embedding(input_dim=len(vocab), output_dim=64)(x)\n",
      "outputs = layers.LSTM(1)(x)\n",
      "model = keras.Model(inputs, outputs)\n",
      "\n",
      "# (알 수 없는 토큰을 포함하는) 평가 데이터 위에서 모델을 호출합니다\n",
      "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
      "test_output = model(test_data)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        \"For put them side by side\",\\n        \"The one the other will contain\",\\n        \"With ease and You beside\",\\n    ]\\n)\\n# \"정수\" 출력 방식으로 TextVectorization을 생성합니다\\ntext_vectorizer = preprocessing.TextVectorization(output_mode=\"int\")\\n# `adapt()`를 통해 사전을 색인합니다\\ntext_vectorizer.adapt(data)\\n\\n# get_vocabulary()를 통해 색인한 사전을 받아올 수 있습니다\\nvocab = text_vectorizer.get_vocabulary()\\nprint(\"Vocabulary:\", vocab)\\n\\n# Embedding + LSTM 모델을 생성합니다\\ninputs = keras.Input(shape=(1,), dtype=\"string\")\\nx = text_vectorizer(inputs)\\nx = layers.Embedding(input_dim=len(vocab), output_dim=64)(x)\\noutputs = layers.LSTM(1)(x)\\nmodel = keras.Model(inputs, outputs)\\n\\n# (알 수 없는 토큰을 포함하는) 평가 데이터 위에서 모델을 호출합니다\\ntest_data = tf.constant([\"The Brain is deeper than the sea\"])\\ntest_output = model(test_data)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 46747, 18537, 8906]\n",
      "\n",
      "4. decode: \n",
      "<s># 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\n",
      "data =</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "# 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\n",
      "data = tf.constant(\n",
      "    [\n",
      "        \"The Brain is wider than the Sky\",\n",
      "        \"For put them side by side\",\n",
      "        \"The one the other will contain\",\n",
      "        \"With ease and You beside\",\n",
      "    ]\n",
      ")\n",
      "# \"binary\" 출력 방식(multi-hot)과 ngram=2(모든 bigram 색인)으로\n",
      "# TextVectorization을 생성합니다\n",
      "text_vectorizer = preprocessing.TextVectorization(output_mode=\"binary\", ngrams=2)\n",
      "# `adapt()`를 통해 bigram들을 색인합니다\n",
      "text_vectorizer.adapt(data)\n",
      "\n",
      "print(\n",
      "    \"Encoded text:\\n\",\n",
      "    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",
      "    \"\\n\",\n",
      ")\n",
      "\n",
      "# Dense 모델을 생성합니다\n",
      "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
      "x = text_vectorizer(inputs)\n",
      "outputs = layers.Dense(1)(x)\n",
      "model = keras.Model(inputs, outputs)\n",
      "\n",
      "# (알 수 없는 토큰을 포함하는) 평가 데이터 위에서 모델을 호출합니다\n",
      "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
      "test_output = model(test_data)\n",
      "\n",
      "print(\"Model output:\", test_output)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        \"For put them side by side\",\\n        \"The one the other will contain\",\\n        \"With ease and You beside\",\\n    ]\\n)\\n# \"binary\" 출력 방식(multi-hot)과 ngram=2(모든 bigram 색인)으로\\n# TextVectorization을 생성합니다\\ntext_vectorizer = preprocessing.TextVectorization(output_mode=\"binary\", ngrams=2)\\n# `adapt()`를 통해 bigram들을 색인합니다\\ntext_vectorizer.adapt(data)\\n\\nprint(\\n    \"Encoded text:\\\\n\",\\n    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\\n    \"\\\\n\",\\n)\\n\\n# Dense 모델을 생성합니다\\ninputs = keras.Input(shape=(1,), dtype=\"string\")\\nx = text_vectorizer(inputs)\\noutputs = layers.Dense(1)(x)\\nmodel = keras.Model(inputs, outputs)\\n\\n# (알 수 없는 토큰을 포함하는) 평가 데이터 위에서 모델을 호출합니다\\ntest_data = tf.constant([\"The Brain is deeper than the sea\"])\\ntest_output = model(test_data)\\n\\nprint(\"Model output:\", test_output)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 46747, 18537, 8906]\n",
      "\n",
      "4. decode: \n",
      "<s># 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\n",
      "data =</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "1. Code Type: code\n",
      "\n",
      "2. og_source: \n",
      "# 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\n",
      "data = tf.constant(\n",
      "    [\n",
      "        \"The Brain is wider than the Sky\",\n",
      "        \"For put them side by side\",\n",
      "        \"The one the other will contain\",\n",
      "        \"With ease and You beside\",\n",
      "    ]\n",
      ")\n",
      "# \"tf-idf\" 출력 방식(TF-IDF 가중치를 사용하는 multi-hot)과 ngram=2(모든 bigram 색인)으로\n",
      "# TextVectorization을 생성합니다\n",
      "text_vectorizer = preprocessing.TextVectorization(output_mode=\"tf-idf\", ngrams=2)\n",
      "# `adapt()`를 통해 bigram들을 색인합니다\n",
      "text_vectorizer.adapt(data)\n",
      "\n",
      "print(\n",
      "    \"Encoded text:\\n\",\n",
      "    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",
      "    \"\\n\",\n",
      ")\n",
      "\n",
      "# Dense 모델을 생성합니다\n",
      "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
      "x = text_vectorizer(inputs)\n",
      "outputs = layers.Dense(1)(x)\n",
      "model = keras.Model(inputs, outputs)\n",
      "\n",
      "# (알 수 없는 토큰을 포함하는) 평가 데이터 위에서 모델을 호출합니다\n",
      "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
      "test_output = model(test_data)\n",
      "\n",
      "print(\"Model output:\", test_output)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. og_source: \\n# 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\\ndata = tf.constant(\\n    [\\n        \"The Brain is wider than the Sky\",\\n        \"For put them side by side\",\\n        \"The one the other will contain\",\\n        \"With ease and You beside\",\\n    ]\\n)\\n# \"tf-idf\" 출력 방식(TF-IDF 가중치를 사용하는 multi-hot)과 ngram=2(모든 bigram 색인)으로\\n# TextVectorization을 생성합니다\\ntext_vectorizer = preprocessing.TextVectorization(output_mode=\"tf-idf\", ngrams=2)\\n# `adapt()`를 통해 bigram들을 색인합니다\\ntext_vectorizer.adapt(data)\\n\\nprint(\\n    \"Encoded text:\\\\n\",\\n    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\\n    \"\\\\n\",\\n)\\n\\n# Dense 모델을 생성합니다\\ninputs = keras.Input(shape=(1,), dtype=\"string\")\\nx = text_vectorizer(inputs)\\noutputs = layers.Dense(1)(x)\\nmodel = keras.Model(inputs, outputs)\\n\\n# (알 수 없는 토큰을 포함하는) 평가 데이터 위에서 모델을 호출합니다\\ntest_data = tf.constant([\"The Brain is deeper than the sea\"])\\ntest_output = model(test_data)\\n\\nprint(\"Model output:\", test_output)\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. encode: \n",
      "[0, 10431, 46747, 18537, 8906]\n",
      "\n",
      "4. decode: \n",
      "<s># 층에 adapt하기 위한 몇가지 텍스트 데이터를 정의합니다\n",
      "data =</s>\n",
      "------------------------- code start--------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_score_sample = total_result.sort_values('kendall_score').iloc[:10,:]\n",
    "# display(low_score_sample)\n",
    "\n",
    "# 실제 인코딩 텍스트 확인\n",
    "def print_incoding_result(cell_tb, notebook_id, label_order, pred_order):\n",
    "    # cell tb 중 확인할 notebook_id sort\n",
    "    tmp_tb = cell_tb[cell_tb.id == notebook_id].copy()\n",
    "    tmp_tb = tmp_tb.set_index('cell_id')\n",
    "\n",
    "    print(f'################### Notebook id: {notebook_id} ###################\\n')\n",
    "\n",
    "    # pred order 대로 cell print\n",
    "#     print(f'>>> pred_order_col result')\n",
    "#     display(tmp_tb.loc[pred_order])\n",
    "    for c_type, label_r, pred_r, t, e_t in tmp_tb.loc[pred_order][['cell_type','rank', 'pred', 'source', 'input_text']].values:\n",
    "        if c_type == 'markdown':\n",
    "            print(f'------------------------- code start--------------------------------------------------------------------------------------')\n",
    "            print(f'{color.YELLOW}1. Code Type:{color.END}{c_type}\\n')\n",
    "            print(f'{color.YELLOW}>> Label rank:{color.END}{label_r}\\n')\n",
    "            print(f'{color.YELLOW}>> Pred rank:{color.END}{pred_r}\\n')     \n",
    "            print(f'{color.YELLOW}2. og text:{color.END} \\n{t}\\n')\n",
    "            print(f'{color.YELLOW}3. input_text:{color.END} \\n{e_t}\\n')\n",
    "#             _encode = tokenizer_forex.encode(t, max_length=md_max_len)\n",
    "#             print(f'4. encode: \\n{_encode[:5]}\\n')        \n",
    "#             print(f'5. decode: \\n{tokenizer_forex.decode(_encode)}')\n",
    "            print(f'------------------------- code end--------------------------------------------------------------------------------------')        \n",
    "        else:\n",
    "            pass\n",
    "    return None\n",
    "print(md_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "row = low_score_sample.iloc[idx]\n",
    "n_id = row.id\n",
    "label_order = row.label_order\n",
    "pred_order = row.pred_order\n",
    "print_incoding_result(new_val_df, n_id, label_order, pred_order)\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea097e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57052080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e803a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77d3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e02cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff72db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93157795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947605f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
